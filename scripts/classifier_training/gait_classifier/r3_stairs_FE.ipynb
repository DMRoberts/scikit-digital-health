{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score, roc_curve, make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from PfyMU.gait.train_classifier.core import load_datasets\n",
    "from PfyMU.features import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfiltfilt\n",
    "\n",
    "\n",
    "def mag_filter(x, fs):\n",
    "    sos = butter(1, 2 * 5 / fs, btype='low', output='sos')\n",
    "    x_ = np.linalg.norm(x, axis=1)\n",
    "    return sosfiltfilt(sos, x_) - 1\n",
    "\n",
    "def mag_band_filter(x, fs):\n",
    "    sos = butter(1, [2 * 0.25 / fs, 2 * 5 / fs], btype='band', output='sos')\n",
    "    return sosfiltfilt(sos, np.linalg.norm(x, axis=1))\n",
    "\n",
    "def lp_filter(x, fs):\n",
    "    sos = butter(1, [0.25 * 2 / fs, 2 * 5 / fs], btype='band', output='sos')\n",
    "    return sosfiltfilt(sos, x, axis=0)\n",
    "    \n",
    "steps = {\n",
    "    'walking': 0.4,\n",
    "    'walking-impaired': 0.2,\n",
    "    'sitting': 900,\n",
    "    'standing': 300,\n",
    "    'stairs-ascending': 0.3,\n",
    "    'stairs-descending': 0.3,\n",
    "    'cycling-50W': 0.3,\n",
    "    'cycling-100W': 0.3,\n",
    "    'default': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gait_sets_path = Path('/Users/adamol/Documents/Datasets/gait/processed')\n",
    "gait_sets_path = Path('/home/lukasadamowicz/Documents/Datasets/processed')\n",
    "\n",
    "datasets = [\n",
    "    gait_sets_path / 'bluesky2',\n",
    "    gait_sets_path / 'daliac',\n",
    "    gait_sets_path / 'ltmm',\n",
    "    gait_sets_path / 'usc-had'\n",
    "]\n",
    "\n",
    "kwargs = {'paths': datasets, 'goal_fs': 50.0, 'window_step': steps, 'window_length': 3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, subjects, activities = load_datasets(acc_mag=False, signal_function=lp_filter, **kwargs)\n",
    "\n",
    "Y[['stair' in i for i in activities]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mf, *_ = load_datasets(acc_mag=False, signal_function=mag_filter, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mbf, *_ = load_datasets(acc_mag=False, signal_function=mag_band_filter, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples (3.0s windows):  43163\n",
      "Total walking samples:  25758\n",
      "Total non-walking samples:  17405 \n",
      "\n",
      "% walking samples: 59.68\n"
     ]
    }
   ],
   "source": [
    "print('Total samples (3.0s windows): ', Y.size)\n",
    "print('Total walking samples: ', Y.sum())\n",
    "print('Total non-walking samples: ', Y.size - Y.sum(), '\\n')\n",
    "print(f'% walking samples: {Y.sum() / Y.size * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit-to-stand             :    16 / 43163    0.00\n",
      "standing-assisted        :   207 / 43163    0.00\n",
      "jumping-rope             :   212 / 43163    0.00\n",
      "jumping                  :   311 / 43163    0.01\n",
      "vacuuming                :   376 / 43163    0.01\n",
      "lying                    :   378 / 43163    0.01\n",
      "elevator-descending      :   475 / 43163    0.01\n",
      "elevator-ascending       :   491 / 43163    0.01\n",
      "running                  :   541 / 43163    0.01\n",
      "sweeping                 :   612 / 43163    0.01\n",
      "running-treadmill        :   755 / 43163    0.02\n",
      "washing-dishes           :   776 / 43163    0.02\n",
      "walking-left             :   787 / 43163    0.02\n",
      "walking-right            :   842 / 43163    0.02\n",
      "sleeping                 :  1126 / 43163    0.03\n",
      "stairs-descending        :  2477 / 43163    0.06\n",
      "cycling-50W              :  2509 / 43163    0.06\n",
      "cycling-100W             :  2515 / 43163    0.06\n",
      "stairs-ascending         :  2763 / 43163    0.06\n",
      "standing                 :  2953 / 43163    0.07\n",
      "sitting                  :  3152 / 43163    0.07\n",
      "walking-impaired         :  8241 / 43163    0.19\n",
      "walking                  : 10648 / 43163    0.25\n"
     ]
    }
   ],
   "source": [
    "unq_act, act_ct = np.unique(activities, return_counts=True)\n",
    "N = np.sum(act_ct)\n",
    "si = np.argsort(act_ct)\n",
    "for a, c in zip(unq_act[si], act_ct[si]):\n",
    "    print(f'{a:25s}: {c:5d} / {N:5d}{c/N:8.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X[i, :, :] = pca.fit_transform(X[i, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "rnd_subjects = [i for i in np.unique(subjects) if np.unique(activities[subjects==i]).size > 3]\n",
    "random.shuffle(rnd_subjects)\n",
    "\n",
    "training_masks, validation_masks, testing_masks = [], [], []\n",
    "\n",
    "for i in range(0, len(rnd_subjects), 4):\n",
    "    trm = np.ones(len(subjects), dtype='bool')\n",
    "    vm = np.zeros_like(trm, dtype='bool')\n",
    "    tem = np.zeros_like(trm, dtype='bool')\n",
    "    \n",
    "    for j in range(4):\n",
    "        trm &= subjects != rnd_subjects[i + j]\n",
    "        if j < 2:\n",
    "            vm |= subjects == rnd_subjects[i + j]\n",
    "        else:\n",
    "            tem |= subjects == rnd_subjects[i + j]\n",
    "    \n",
    "    training_masks.append(trm)\n",
    "    validation_masks.append(vm)\n",
    "    testing_masks.append(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = Bank(window_length=None, window_step=None)\n",
    "\n",
    "# add features\n",
    "FB + Mean()\n",
    "FB + MeanCrossRate()\n",
    "# FB + StdDev()  # highly correlated with RMS\n",
    "FB + Skewness()\n",
    "FB + Kurtosis()\n",
    "FB + Range()\n",
    "FB + IQR()\n",
    "FB + RMS()\n",
    "FB + LinearSlope()\n",
    "FB + SignalEntropy()\n",
    "FB + SPARC()\n",
    "FB + ComplexityInvariantDistance(normalize=True)\n",
    "FB + JerkMetric(normalize=True)\n",
    "FB + DimensionlessJerk(log=True, signal_type='acceleration')\n",
    "\n",
    "FB + Autocorrelation(lag=15, normalize=True)\n",
    "FB + SampleEntropy(m=2, r=0.5)\n",
    "FB + PermutationEntropy(order=3, delay=1, normalize=True)\n",
    "FB + RangeCountPercentage(range_min=0.4, range_max=1.5)\n",
    "FB + RangeCountPercentage(range_min=-0.5, range_max=0.5)\n",
    "FB + DominantFrequency(low_cutoff=1.0, high_cutoff=3.5)\n",
    "FB + DominantFrequencyValue(low_cutoff=0.25, high_cutoff=5.0)\n",
    "FB + PowerSpectralSum(low_cutoff=1.0, high_cutoff=3.5)\n",
    "FB + SpectralFlatness(low_cutoff=0.0, high_cutoff=6.0)\n",
    "FB + SpectralEntropy(low_cutoff=0.0, high_cutoff=5.0)\n",
    "FB + DetailPowerRatio(wavelet='coif4', freq_band=[1.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_pca, feature_names = FB.compute(X, fs=50.0, windowed=True, columns=['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mf, mf_fnames = FB.compute(X_mf, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mbf, mbf_fnames = FB.compute(X_mbf, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_pca = pd.DataFrame(data={'Label': Y}, columns=['Label'] + feature_names)\n",
    "feats_pca.iloc[:, 1:] = X_pca\n",
    "\n",
    "feats_mf = pd.DataFrame(data={'Label': Y}, columns=['Label'] + mf_fnames)\n",
    "feats_mf.iloc[:, 1:] = X_mf\n",
    "\n",
    "feats_mbf = pd.DataFrame(data={'Label': Y}, columns=['Label'] + mbf_fnames)\n",
    "feats_mbf.iloc[:, 1:] = X_mbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcd0b769c9e46398b746cbbe75011cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_predictors = ppscore.predictors(feats_pca, 'Label', output='df')\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.barplot(data=pca_predictors, x=\"x\", y=\"ppscore\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399683fd8a7646f1a89abedfea92c841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf_predictors = ppscore.predictors(feats_mf, 'Label', output='df')\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.barplot(data=mf_predictors, x=\"x\", y=\"ppscore\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096cd0851fe74567a06eb238c2de5186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mbf_predictors = ppscore.predictors(feats_mbf, 'Label', output='df')\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = sns.barplot(data=mbf_predictors, x=\"x\", y=\"ppscore\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(learning_rate=0.2, random_state=12049)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminating PCA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)}\n",
    "\n",
    "bacc = []\n",
    "f1 = []\n",
    "\n",
    "pca_features = pca_predictors.x.tolist()\n",
    "\n",
    "for i in range(len(pca_features), 0, -1):\n",
    "    scores = cross_validate(\n",
    "        lgb_model,\n",
    "        feats_pca.loc[:, pca_features[:i]].values,\n",
    "        Y,\n",
    "        scoring=scoring,\n",
    "        cv=zip(training_masks, validation_masks),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    bacc.append(np.nanmean(scores['test_bal_acc']) * 100)\n",
    "    f1.append(np.nanmean(scores['test_F1']) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ede5fbfde0412abf4932d731ec4e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(np.arange(len(f1), 0, -1), bacc, label='Bal. Acc.')\n",
    "ax.plot(np.arange(len(f1), 0, -1), f1, label='F1')\n",
    "f.tight_layout()\n",
    "f.savefig('feature_elimination/pca_w-stairs_features_elimination_pps.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminating filtered magnitude features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)}\n",
    "\n",
    "bacc = []\n",
    "f1 = []\n",
    "\n",
    "mf_features = mf_predictors.x.tolist()\n",
    "\n",
    "for i in range(len(mf_features), 0, -1):\n",
    "    scores = cross_validate(\n",
    "        lgb_model,\n",
    "        feats_mf.loc[:, mf_features[:i]].values,\n",
    "        Y,\n",
    "        scoring=scoring,\n",
    "        cv=zip(training_masks, validation_masks),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    bacc.append(np.nanmean(scores['test_bal_acc']) * 100)\n",
    "    f1.append(np.nanmean(scores['test_F1']) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79393205eb5943968bad35473d09924b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(np.arange(len(f1), 0, -1), bacc, label='Bal. Acc.')\n",
    "ax.plot(np.arange(len(f1), 0, -1), f1, label='F1')\n",
    "f.tight_layout()\n",
    "f.savefig('feature_elimination/filt-mag-1_w-stairs_features_elimination_pps.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminating band filtered magnitude features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)}\n",
    "\n",
    "bacc = []\n",
    "f1 = []\n",
    "\n",
    "mbf_features = mbf_predictors.x.tolist()\n",
    "\n",
    "for i in range(len(mbf_features), 0, -1):\n",
    "    scores = cross_validate(\n",
    "        lgb_model,\n",
    "        feats_mbf.loc[:, mbf_features[:i]].values,\n",
    "        Y,\n",
    "        scoring=scoring,\n",
    "        cv=zip(training_masks, validation_masks),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    bacc.append(np.nanmean(scores['test_bal_acc']) * 100)\n",
    "    f1.append(np.nanmean(scores['test_F1']) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864cecd758794980b9f61a0542423b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(np.arange(len(f1), 0, -1), bacc, label='Bal. Acc.')\n",
    "ax.plot(np.arange(len(f1), 0, -1), f1, label='F1')\n",
    "f.tight_layout()\n",
    "f.savefig('feature_elimination/band-filter_w-stairs_features_elimination_pps.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbf_features[:18]\n",
    "\n",
    "with open('lgb_features.txt', 'w') as f:\n",
    "    for ft in mbf_features[:18]:\n",
    "        f.write(ft + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921219527085372\n",
      "0.892434331501833\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    lgb_model,\n",
    "    feats_mbf.loc[:, mbf_features[:18]].values,\n",
    "    Y,\n",
    "    scoring=scoring,\n",
    "    cv=zip(training_masks, validation_masks),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(np.mean(scores['test_bal_acc']))\n",
    "print(np.mean(scores['test_F1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
