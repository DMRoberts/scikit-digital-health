{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../feature_exploration/features.h5', key='incl_stairs')\n",
    "\n",
    "feats = data.iloc[:, 3:]\n",
    "labels = data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the subjects for which LOSO actually makes sense: those with multiple activities (ie more than just walking)\n",
    "gbc = data.groupby(['Subject', 'Activity'], as_index=False).count()\n",
    "loso_subjects = [i for i in gbc.Subject.unique() if gbc.loc[gbc.Subject == i].shape[0] > 3]\n",
    "\n",
    "random.seed(5)  # fix the generation so that its the same every time\n",
    "random.shuffle(loso_subjects)\n",
    "\n",
    "training_masks = []\n",
    "validation_masks = []\n",
    "testing_masks = []\n",
    "\n",
    "for i in range(0, len(loso_subjects), 4):\n",
    "    tr_m = np.ones(data.shape[0], dtype='bool')\n",
    "    v_m = np.zeros(data.shape[0], dtype='bool')\n",
    "    te_m = np.zeros(data.shape[0], dtype='bool')\n",
    "    \n",
    "    for j in range(4):\n",
    "        tr_m &= (data.Subject != loso_subjects[i+j]).values\n",
    "    for j in range(2):\n",
    "        v_m |= (data.Subject == loso_subjects[i+j]).values\n",
    "    for j in range(2):\n",
    "        te_m |= (data.Subject == loso_subjects[i+j+2]).values\n",
    "    \n",
    "    training_masks.append(tr_m)\n",
    "    validation_masks.append(v_m)\n",
    "    testing_masks.append(te_m)\n",
    "\n",
    "masks = (training_masks, validation_masks, testing_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.13   Balanced Accuracy: 99.07   F1: 98.58\n",
      "Accuracy: 98.40   Balanced Accuracy: 98.80   F1: 96.98\n",
      "Accuracy: 96.88   Balanced Accuracy: 96.59   F1: 94.04\n",
      "Accuracy: 96.65   Balanced Accuracy: 97.57   F1: 94.10\n",
      "Accuracy: 85.31   Balanced Accuracy: 86.80   F1: 85.47\n",
      "Accuracy: 88.23   Balanced Accuracy: 88.70   F1: 87.89\n",
      "Accuracy: 98.40   Balanced Accuracy: 98.50   F1: 98.71\n",
      "Accuracy: 98.62   Balanced Accuracy: 98.73   F1: 98.72\n",
      "Accuracy: 97.91   Balanced Accuracy: 97.99   F1: 97.20\n",
      "Accuracy: 98.53   Balanced Accuracy: 98.25   F1: 98.88\n",
      "Accuracy: 90.22   Balanced Accuracy: 92.92   F1: 86.06\n",
      "\n",
      " --------------------------------------------------\n",
      "Mean Accuracy: 95.30  Mean Bal. Acc.: 95.81  Mean F1: 94.24\n"
     ]
    }
   ],
   "source": [
    "acc, bacc, f1 = [], [], [] \n",
    "for trm, vm in zip(training_masks, validation_masks):\n",
    "    clf = lgb.LGBMClassifier(learning_rate=0.2, random_state=42)\n",
    "\n",
    "    clf.fit(feats.loc[trm], labels[trm]);\n",
    "    y_pred = clf.predict(feats.loc[vm])\n",
    "\n",
    "    acc.append(accuracy_score(labels[vm], y_pred))\n",
    "    bacc.append(balanced_accuracy_score(labels[vm], y_pred))\n",
    "    f1.append(f1_score(labels[vm], y_pred))\n",
    "\n",
    "    print(f'Accuracy: {acc[-1]*100:.2f}   Balanced Accuracy: {bacc[-1]*100:.2f}   F1: {f1[-1]*100:.2f}')\n",
    "\n",
    "print('\\n', '-'*50)\n",
    "print(f'Mean Accuracy: {np.mean(acc)*100:.2f}  Mean Bal. Acc.: {np.mean(bacc)*100:.2f}  Mean F1: {np.mean(f1)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10  Accuracy: 94.37   Balanced Accuracy: 95.15   F1: 92.98\n",
      " 20  Accuracy: 94.62   Balanced Accuracy: 95.33   F1: 93.31\n",
      " 40  Accuracy: 95.00   Balanced Accuracy: 95.57   F1: 93.86\n",
      " 50  Accuracy: 95.17   Balanced Accuracy: 95.71   F1: 94.05\n",
      " 60  Accuracy: 95.16   Balanced Accuracy: 95.69   F1: 94.06\n",
      " 65  Accuracy: 95.24   Balanced Accuracy: 95.75   F1: 94.16\n",
      " 70  Accuracy: 95.28   Balanced Accuracy: 95.80   F1: 94.20\n",
      " 75  Accuracy: 95.33   Balanced Accuracy: 95.85   F1: 94.26\n",
      " 80  Accuracy: 95.30   Balanced Accuracy: 95.83   F1: 94.22\n",
      " 90  Accuracy: 95.30   Balanced Accuracy: 95.82   F1: 94.23\n",
      "100  Accuracy: 95.30   Balanced Accuracy: 95.81   F1: 94.24\n",
      "125  Accuracy: 95.38   Balanced Accuracy: 95.89   F1: 94.35\n"
     ]
    }
   ],
   "source": [
    "acc, bacc, f1 = [], [], []\n",
    "\n",
    "n_estimators = np.array([10, 20, 40, 50, 60, 65, 70, 75, 80, 90, 100, 125])\n",
    "\n",
    "for n_est in n_estimators:\n",
    "    acc.append([])\n",
    "    bacc.append([])\n",
    "    f1.append([])\n",
    "    for trm, vm in zip(training_masks, validation_masks):\n",
    "        clf = lgb.LGBMClassifier(learning_rate=0.2, n_estimators=n_est, random_state=42)\n",
    "\n",
    "        clf.fit(feats.loc[trm], labels[trm]);\n",
    "        y_pred = clf.predict(feats.loc[vm])\n",
    "\n",
    "        acc[-1].append(accuracy_score(labels[vm], y_pred))\n",
    "        bacc[-1].append(balanced_accuracy_score(labels[vm], y_pred))\n",
    "        f1[-1].append(f1_score(labels[vm], y_pred))\n",
    "    \n",
    "    print(f'{n_est:3d}  Accuracy: {np.mean(acc[-1])*100:.2f}   Balanced Accuracy: {np.mean(bacc[-1])*100:.2f}   F1: {np.mean(f1[-1])*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdac5d4e80f44449c2b255a2da3da23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "macc = np.array([np.mean(i) for i in acc])\n",
    "mbacc = np.array([np.mean(i) for i in bacc])\n",
    "mf1 = np.array([np.mean(i) for i in f1])\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.plot(n_estimators, macc * 100, '.-', label='Accuracy')\n",
    "ax.plot(n_estimators, mbacc * 100, '.-', label='Balanced Accuracy')\n",
    "ax.plot(n_estimators, mf1 * 100, '.-', label='F1')\n",
    "\n",
    "axx = ax.twinx()\n",
    "axx.grid(False)\n",
    "axx.plot(n_estimators[1:], np.diff(macc) / macc[:-1] * 100, '.--')\n",
    "axx.plot(n_estimators[1:], np.diff(mbacc) / mbacc[:-1] * 100, '.--')\n",
    "axx.plot(n_estimators[1:], np.diff(mf1) / mf1[:-1] * 100, '.--')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('# Estimators')\n",
    "ax.set_ylabel('% Score')\n",
    "axx.set_ylabel('% Score Change')\n",
    "\n",
    "f.tight_layout()\n",
    "\n",
    "# f.savefig('lightgbm_n-estimators_performance.png', bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
