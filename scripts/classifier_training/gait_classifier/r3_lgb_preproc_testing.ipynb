{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score, roc_curve, make_scorer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from PfyMU.gait.train_classifier.core import load_datasets\n",
    "from PfyMU.features import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfiltfilt\n",
    "\n",
    "def pca_func(x, fs):\n",
    "    pca = PCA(n_components=3)\n",
    "    \n",
    "    return pca.fit_transform(x)\n",
    "\n",
    "\n",
    "def vert_acc_func(x, fs):\n",
    "    sos = butter(4, 2 * 0.8 / fs, btype='low', output='sos')\n",
    "    g_est = sosfiltfilt(sos, x, axis=0)\n",
    "    \n",
    "    return np.sum(x * g_est, axis=1)\n",
    "\n",
    "\n",
    "def mag_filter(x, fs):\n",
    "    sos = butter(1, 2 * 5 / fs, btype='low', output='sos')\n",
    "    x_ = np.linalg.norm(x, axis=1)\n",
    "    return sosfiltfilt(sos, x_) - 1\n",
    "#     return x_ - 1\n",
    "\n",
    "def mag_band_filter(x, fs):\n",
    "    sos = butter(4, [2 * 0.25 / fs, 2 * 5 / fs], btype='band', output='sos')\n",
    "#     sos = butter(4, 2*5/fs, output='sos')\n",
    "    x_ = np.linalg.norm(x, axis=1)\n",
    "\n",
    "    return sosfiltfilt(sos, x_)\n",
    "\n",
    "def band_filter(x, fs):\n",
    "    sos = butter(4, [2 * 0.25 / fs, 2 * 5 / fs], btype='band', output='sos')\n",
    "    return sosfiltfilt(sos, x, axis=0)\n",
    "    \n",
    "steps = {\n",
    "    'walking': 0.4,\n",
    "    'walking-impaired': 0.2,\n",
    "    'sitting': 900,\n",
    "    'standing': 300,\n",
    "    'stairs-ascending': 0.3,\n",
    "    'stairs-descending': 0.3,\n",
    "    'cycling-50W': 0.3,\n",
    "    'cycling-100W': 0.3,\n",
    "    'default': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gait_sets_path = Path('/Users/adamol/Documents/Datasets/gait/processed')\n",
    "gait_sets_path = Path('/home/lukasadamowicz/Documents/Datasets/processed')\n",
    "\n",
    "datasets = [\n",
    "    gait_sets_path / 'bluesky2',\n",
    "    gait_sets_path / 'daliac',\n",
    "    gait_sets_path / 'ltmm',\n",
    "    gait_sets_path / 'usc-had'\n",
    "]\n",
    "\n",
    "kwargs = {'paths': datasets, 'goal_fs': 50.0, 'window_step': steps, 'window_length': 3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, subjects, activities = load_datasets(acc_mag=False, signal_function=pca_func, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vacc, _, _, _ = load_datasets(acc_mag=False, signal_function=vert_acc_func, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_none, _, _, _ = load_datasets(acc_mag=False, signal_function=None, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mf, *_ = load_datasets(acc_mag=False, signal_function=mag_filter, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mbf, *_ = load_datasets(acc_mag=False, signal_function=mag_band_filter, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "ratio_1_2 = np.zeros(X_none.shape[0])\n",
    "\n",
    "for i in range(X_none.shape[0]):\n",
    "    X_none[i, :, :] = pca.fit_transform(X_none[i, :, :])\n",
    "    ratio_1_2[i] = pca.explained_variance_ratio_[1] / pca.explained_variance_ratio_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples (3.0s windows):  43163\n",
      "Total walking samples:  20518\n",
      "Total non-walking samples:  22645 \n",
      "\n",
      "% walking samples: 47.54\n"
     ]
    }
   ],
   "source": [
    "print('Total samples (3.0s windows): ', Y.size)\n",
    "print('Total walking samples: ', Y.sum())\n",
    "print('Total non-walking samples: ', Y.size - Y.sum(), '\\n')\n",
    "print(f'% walking samples: {Y.sum() / Y.size * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sit-to-stand             :    16 / 43163    0.00\n",
      "standing-assisted        :   207 / 43163    0.00\n",
      "jumping-rope             :   212 / 43163    0.00\n",
      "jumping                  :   311 / 43163    0.01\n",
      "vacuuming                :   376 / 43163    0.01\n",
      "lying                    :   378 / 43163    0.01\n",
      "elevator-descending      :   475 / 43163    0.01\n",
      "elevator-ascending       :   491 / 43163    0.01\n",
      "running                  :   541 / 43163    0.01\n",
      "sweeping                 :   612 / 43163    0.01\n",
      "running-treadmill        :   755 / 43163    0.02\n",
      "washing-dishes           :   776 / 43163    0.02\n",
      "walking-left             :   787 / 43163    0.02\n",
      "walking-right            :   842 / 43163    0.02\n",
      "sleeping                 :  1126 / 43163    0.03\n",
      "stairs-descending        :  2477 / 43163    0.06\n",
      "cycling-50W              :  2509 / 43163    0.06\n",
      "cycling-100W             :  2515 / 43163    0.06\n",
      "stairs-ascending         :  2763 / 43163    0.06\n",
      "standing                 :  2953 / 43163    0.07\n",
      "sitting                  :  3152 / 43163    0.07\n",
      "walking-impaired         :  8241 / 43163    0.19\n",
      "walking                  : 10648 / 43163    0.25\n"
     ]
    }
   ],
   "source": [
    "unq_act, act_ct = np.unique(activities, return_counts=True)\n",
    "N = np.sum(act_ct)\n",
    "si = np.argsort(act_ct)\n",
    "for a, c in zip(unq_act[si], act_ct[si]):\n",
    "    print(f'{a:25s}: {c:5d} / {N:5d}{c/N:8.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(398)\n",
    "rnd_subjects = [i for i in np.unique(subjects) if np.unique(activities[subjects==i]).size > 3]\n",
    "random.shuffle(rnd_subjects)\n",
    "\n",
    "training_masks, validation_masks, testing_masks = [], [], []\n",
    "\n",
    "for i in range(0, len(rnd_subjects), 4):\n",
    "    trm = np.ones(len(subjects), dtype='bool')\n",
    "    vm = np.zeros_like(trm, dtype='bool')\n",
    "    tem = np.zeros_like(trm, dtype='bool')\n",
    "    \n",
    "    for j in range(4):\n",
    "        trm &= subjects != rnd_subjects[i + j]\n",
    "        if j < 2:\n",
    "            vm |= subjects == rnd_subjects[i + j]\n",
    "        else:\n",
    "            tem |= subjects == rnd_subjects[i + j]\n",
    "    \n",
    "    training_masks.append(trm)\n",
    "    validation_masks.append(vm)\n",
    "    testing_masks.append(tem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = Bank(window_length=None, window_step=None)\n",
    "\n",
    "# add features\n",
    "FB + Mean()\n",
    "FB + MeanCrossRate()\n",
    "# FB + StdDev()  # highly correlated with RMS\n",
    "FB + Skewness()\n",
    "FB + Kurtosis()\n",
    "FB + Range()\n",
    "FB + IQR()\n",
    "FB + RMS()\n",
    "FB + LinearSlope()\n",
    "FB + SignalEntropy()\n",
    "FB + SPARC()\n",
    "FB + ComplexityInvariantDistance(normalize=True)\n",
    "FB + JerkMetric(normalize=True)\n",
    "FB + DimensionlessJerk(log=True, signal_type='acceleration')\n",
    "\n",
    "FB + Autocorrelation(lag=15, normalize=True)\n",
    "FB + SampleEntropy(m=2, r=0.5)\n",
    "FB + PermutationEntropy(order=3, delay=1, normalize=True)\n",
    "FB + RangeCountPercentage(range_min=0.4, range_max=1.5)\n",
    "FB + RangeCountPercentage(range_min=-0.5, range_max=0.5)\n",
    "FB + DominantFrequency(low_cutoff=1.0, high_cutoff=3.5)\n",
    "FB + DominantFrequencyValue(low_cutoff=0.25, high_cutoff=5.0)\n",
    "FB + PowerSpectralSum(low_cutoff=1.0, high_cutoff=3.5)\n",
    "FB + SpectralFlatness(low_cutoff=0.0, high_cutoff=6.0)\n",
    "FB + SpectralEntropy(low_cutoff=0.0, high_cutoff=5.0)\n",
    "FB + DetailPowerRatio(wavelet='coif4', freq_band=[1.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_feat, feature_names = FB.compute(X, fs=50.0, windowed=True, columns=['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacc_feat, vacc_fnames = FB.compute(X_vacc, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_pca, featuture_names = FB.compute(X_none, fs=50.0, windowed=True, columns=['PC1', 'PC2', 'PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mf, mf_fnames = FB.compute(X_mf, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mbf2, mft_fnames = FB.compute(X_mbf, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43163, 24) (43163, 150)\n"
     ]
    }
   ],
   "source": [
    "print(vacc_feat.shape, X_vacc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43163, 72) (43163, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_feat.shape, X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(learning_rate=0.2, random_state=12049)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA before windowing\n",
    "\n",
    "Probably not the best approach since the activities are split up, compared to use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bal. Acc.: 93.79  Mean F1: 91.70\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    lgb_model,\n",
    "    X_feat,\n",
    "    Y,\n",
    "    scoring={'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)},\n",
    "    cv=zip(training_masks, validation_masks),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Mean Bal. Acc.: {np.mean(scores[\"test_bal_acc\"])*100:.2f}  Mean F1: {np.mean(scores[\"test_F1\"])*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax, ax1) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "\n",
    "i = 1\n",
    "for fp, tp, tr in zip(fpr, tpr, trsh):\n",
    "    ax.plot(fp, tp, label=f'Fold {i}')\n",
    "    ax1.plot(tr, np.sqrt(fp**2 + (1 - tp)**2))\n",
    "    i += 1\n",
    "\n",
    "ax1.set_xlim(-0.05, 1.05)\n",
    "ax.legend()\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertical Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bal. Acc.: 90.53  Mean F1: 87.28\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    lgb_model,\n",
    "    vacc_feat,\n",
    "    Y,\n",
    "    scoring={'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)},\n",
    "    cv=zip(training_masks, validation_masks),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Mean Bal. Acc.: {np.mean(scores[\"test_bal_acc\"])*100:.2f}  Mean F1: {np.mean(scores[\"test_F1\"])*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA but after windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bal. Acc.: 93.15  Mean F1: 90.81\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    lgb_model,\n",
    "    X_pca,\n",
    "    Y,\n",
    "    scoring={'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)},\n",
    "    cv=zip(training_masks, validation_masks),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Mean Bal. Acc.: {np.mean(scores[\"test_bal_acc\"])*100:.2f}  Mean F1: {np.mean(scores[\"test_F1\"])*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration Magnitude minus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43163, 24)\n",
      "Mean Bal. Acc.: 92.13  Mean F1: 89.24\n"
     ]
    }
   ],
   "source": [
    "print(X_mf.shape)\n",
    "\n",
    "scores = cross_validate(\n",
    "    lgb_model,\n",
    "    X_mf,\n",
    "    Y,\n",
    "    scoring={'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)},\n",
    "    cv=zip(training_masks, validation_masks),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Mean Bal. Acc.: {np.mean(scores[\"test_bal_acc\"])*100:.2f}  Mean F1: {np.mean(scores[\"test_F1\"])*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtered Acceleration Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Bal. Acc.: 90.90  Mean F1: 87.14\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(\n",
    "    lgb_model,\n",
    "    X_mbf,\n",
    "    Y,\n",
    "    scoring={'F1': make_scorer(f1_score), 'bal_acc': make_scorer(balanced_accuracy_score)},\n",
    "    cv=zip(training_masks, validation_masks),\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Mean Bal. Acc.: {np.mean(scores[\"test_bal_acc\"])*100:.2f}  Mean F1: {np.mean(scores[\"test_F1\"])*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mft_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
