{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from PfyMU.gait.train_classifier.core import load_datasets\n",
    "from PfyMU.features import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_filter(x, fs):\n",
    "    sos = butter(\n",
    "        1, \n",
    "        [2 * 0.5 / fs, 2 * 3 / fs], \n",
    "        btype='band', \n",
    "        output='sos'\n",
    "    )\n",
    "    \n",
    "    return sosfiltfilt(sos, x, axis=0)\n",
    "\n",
    "steps = {\n",
    "    'walking': 0.4,\n",
    "    'walking-impaired': 0.2,\n",
    "    'sitting': 900,\n",
    "    'standing': 300,\n",
    "    'stairs-ascending': 0.3,\n",
    "    'stairs-descending': 0.3,\n",
    "    'cycling-50W': 0.3,\n",
    "    'cycling-100W': 0.3,\n",
    "    'default': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/home/lukasadamowicz/Documents/Datasets/processed')\n",
    "\n",
    "datasets = [\n",
    "    base_path / 'bluesky2',\n",
    "    base_path / 'daliac',\n",
    "    base_path / 'ltmm',\n",
    "    base_path / 'usc-had'\n",
    "]\n",
    "\n",
    "X_, Y, subjects, activities = load_datasets(\n",
    "    paths=datasets,\n",
    "    goal_fs=50.0,\n",
    "    window_length=3.0,\n",
    "    window_step=steps,\n",
    "    acc_mag=False,\n",
    "    signal_function=band_filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nf, _, _, _ = load_datasets(\n",
    "    paths=datasets,\n",
    "    goal_fs=50.0,\n",
    "    window_length=3.0,\n",
    "    window_step=steps,\n",
    "    acc_mag=False,\n",
    "    signal_function=None\n",
    ")\n",
    "\n",
    "x_mn = Mean().compute(x_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros(X_.shape[:-1])\n",
    "for subj in np.unique(subjects):\n",
    "    mask = (subjects == subj) & ((activities == 'walking-impaired') | (activities == 'walking'))\n",
    "    if mask.sum() == 0:\n",
    "        print('no mask')\n",
    "    idx = np.argmax(np.abs(np.sum(x_mn[mask], axis=0)))\n",
    "    \n",
    "    if np.sum(x_mn[mask], axis=0)[idx] < 0:\n",
    "        X[subjects == subj] = X_[subjects == subj, :, idx]\n",
    "    else:\n",
    "        X[subjects == subj] = -1 * X_[subjects == subj, :, idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomize validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "rnd_subjects = [i for i in np.unique(subjects) if np.unique(activities[subjects==i]).size > 3]\n",
    "random.shuffle(rnd_subjects)\n",
    "\n",
    "training_masks, validation_masks, testing_masks = [], [], []\n",
    "\n",
    "for i in range(0, len(rnd_subjects), 4):\n",
    "    trm = np.ones(len(subjects), dtype='bool')\n",
    "    vm = np.zeros_like(trm, dtype='bool')\n",
    "    tem = np.zeros_like(trm, dtype='bool')\n",
    "    \n",
    "    for j in range(4):\n",
    "        trm &= subjects != rnd_subjects[i + j]\n",
    "        if j < 2:\n",
    "            vm |= subjects == rnd_subjects[i + j]\n",
    "        else:\n",
    "            tem |= subjects == rnd_subjects[i + j]\n",
    "    \n",
    "    training_masks.append(trm)\n",
    "    validation_masks.append(vm)\n",
    "    testing_masks.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = Bank(window_length=None, window_step=None)\n",
    "\n",
    "FB + PowerSpectralSum(low_cutoff=0.0, high_cutoff=12.0)\n",
    "FB + DominantFrequency(low_cutoff=0.0, high_cutoff=12.0)\n",
    "FB + MeanCrossRate()\n",
    "FB + Range()\n",
    "FB + RMS()\n",
    "FB + SignalEntropy()\n",
    "FB + SpectralEntropy(low_cutoff=0.0, high_cutoff=12.0)\n",
    "FB + SpectralFlatness(low_cutoff=0.0, high_cutoff=12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat, fnames = FB.compute(X, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.18.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.18.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('gaitpy_v1/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance\n",
      "F1:   84.7  TP:  100.0  FP:   26.0\n",
      "F1:   55.5  TP:  100.0  FP:   59.0\n",
      "F1:   62.6  TP:   98.9  FP:   50.5\n",
      "F1:   50.0  TP:  100.0  FP:   70.1\n",
      "F1:   92.8  TP:   89.9  FP:    9.0\n",
      "F1:   99.2  TP:  100.0  FP:    3.2\n",
      "F1:   69.6  TP:   99.9  FP:   59.5\n",
      "F1:   80.8  TP:   99.6  FP:   48.9\n",
      "F1:   63.5  TP:  100.0  FP:   65.6\n",
      "F1:   62.8  TP:  100.0  FP:   53.7\n",
      "F1:   63.2  TP:  100.0  FP:   50.4\n",
      "\n",
      " --------------------------------------------------\n",
      "Mean (SD) F1: 71.3(15.1)\n",
      "Mean (SD) TP: 98.9(2.9)\n",
      "Mean (SD) FP: 45.1(21.4)\n"
     ]
    }
   ],
   "source": [
    "f1, tp, fp = [], [], []\n",
    "\n",
    "print('Validation set performance')\n",
    "for trm, vm, tem in zip(training_masks, validation_masks, testing_masks):\n",
    "    y_pred = model.predict_proba(X_feat[vm])[:, 1]\n",
    "    \n",
    "    # compute metrics\n",
    "    f1.append(f1_score(Y[vm], y_pred > thresh))\n",
    "    tp.append((Y[vm] & (y_pred > thresh)).sum() / Y[vm].sum())\n",
    "    fp.append((~Y[vm].astype(bool) & (y_pred > thresh)).sum() / (Y[vm].size - Y[vm].sum()))\n",
    "    \n",
    "    print(f'F1: {f1[-1]*100:6.1f}', end='')\n",
    "    print(f'  TP: {tp[-1]*100:6.1f}', end='')\n",
    "    print(f'  FP: {fp[-1]*100:6.1f}')\n",
    "    \n",
    "print('\\n', '-' * 50)\n",
    "print(f'Mean (SD) F1: {np.mean(f1)*100:.1f}({np.std(f1)*100:.1f})')\n",
    "print(f'Mean (SD) TP: {np.mean(tp)*100:.1f}({np.std(tp)*100:.1f})')\n",
    "print(f'Mean (SD) FP: {np.mean(fp)*100:.1f}({np.std(fp)*100:.1f})')\n",
    "\n",
    "df = pd.DataFrame(columns=['Model', 'Metric', 'Score'])\n",
    "df['Metric'] = ['F1'] * len(f1) + ['TP'] * len(tp) + ['FP'] * len(fp)\n",
    "df['Score'] = f1 + tp + fp\n",
    "df['Model'] = 'V1'\n",
    "\n",
    "df.to_csv('v1_validation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set performance\n",
      "F1:   89.5  TP:   95.1  FP:   17.7\n",
      "F1:   63.5  TP:  100.0  FP:   46.6\n",
      "F1:   85.1  TP:  100.0  FP:   29.2\n",
      "F1:   70.0  TP:   99.9  FP:   53.5\n",
      "F1:   53.9  TP:  100.0  FP:   75.2\n",
      "F1:   48.9  TP:   63.4  FP:   65.7\n",
      "F1:   66.4  TP:  100.0  FP:   66.8\n",
      "F1:   51.0  TP:  100.0  FP:   60.6\n",
      "F1:   76.6  TP:   67.0  FP:   10.0\n",
      "F1:   89.8  TP:   98.6  FP:   24.9\n",
      "F1:   61.1  TP:  100.0  FP:   61.9\n",
      "\n",
      " --------------------------------------------------\n",
      "Mean (SD) F1: 68.7(14.2)\n",
      "Mean (SD) TP: 93.1(13.2)\n",
      "Mean (SD) FP: 46.6(21.4)\n"
     ]
    }
   ],
   "source": [
    "f1, tp, fp = [], [], []\n",
    "\n",
    "print('Test set performance')\n",
    "for trm, vm, tem in zip(training_masks, validation_masks, testing_masks):\n",
    "    y_pred = model.predict_proba(X_feat[tem])[:, 1]\n",
    "    \n",
    "    # compute metrics\n",
    "    f1.append(f1_score(Y[tem], y_pred > thresh))\n",
    "    tp.append((Y[tem] & (y_pred > thresh)).sum() / Y[tem].sum())\n",
    "    fp.append((~Y[tem].astype(bool) & (y_pred > thresh)).sum() / (Y[tem].size - Y[tem].sum()))\n",
    "    \n",
    "    print(f'F1: {f1[-1]*100:6.1f}', end='')\n",
    "    print(f'  TP: {tp[-1]*100:6.1f}', end='')\n",
    "    print(f'  FP: {fp[-1]*100:6.1f}')\n",
    "    \n",
    "print('\\n', '-' * 50)\n",
    "print(f'Mean (SD) F1: {np.mean(f1)*100:.1f}({np.std(f1)*100:.1f})')\n",
    "print(f'Mean (SD) TP: {np.mean(tp)*100:.1f}({np.std(tp)*100:.1f})')\n",
    "print(f'Mean (SD) FP: {np.mean(fp)*100:.1f}({np.std(fp)*100:.1f})')\n",
    "\n",
    "df = pd.DataFrame(columns=['Model', 'Metric', 'Score'])\n",
    "df['Metric'] = ['F1'] * len(f1) + ['TP'] * len(tp) + ['FP'] * len(fp)\n",
    "df['Score'] = f1 + tp + fp\n",
    "df['Model'] = 'V1'\n",
    "\n",
    "df.to_csv('v1_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Fold 1 | 89.5 | 95.1 | 17.7 |\n",
      "| Fold 2 | 63.5 | 100.0 | 46.6 |\n",
      "| Fold 3 | 85.1 | 100.0 | 29.2 |\n",
      "| Fold 4 | 70.0 | 99.9 | 53.5 |\n",
      "| Fold 5 | 53.9 | 100.0 | 75.2 |\n",
      "| Fold 6 | 48.9 | 63.4 | 65.7 |\n",
      "| Fold 7 | 66.4 | 100.0 | 66.8 |\n",
      "| Fold 8 | 51.0 | 100.0 | 60.6 |\n",
      "| Fold 9 | 76.6 | 67.0 | 10.0 |\n",
      "| Fold 10 | 89.8 | 98.6 | 24.9 |\n",
      "| Fold 11 | 61.1 | 100.0 | 61.9 |\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "for i, j, k in zip(f1, tp, fp):\n",
    "    print(f'| Fold {c} | {i*100:.1f} | {j*100:.1f} | {k*100:.1f} |')\n",
    "    c += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
