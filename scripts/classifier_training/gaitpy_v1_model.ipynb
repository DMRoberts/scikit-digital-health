{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from PfyMU.gait.train_classifier.core import load_datasets\n",
    "from PfyMU.features import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def band_filter(x, fs):\n",
    "    sos = butter(\n",
    "        1, \n",
    "        [2 * 0.5 / fs, 2 * 3 / fs], \n",
    "        btype='band', \n",
    "        output='sos'\n",
    "    )\n",
    "    \n",
    "    return sosfiltfilt(sos, x, axis=0)\n",
    "\n",
    "steps = {\n",
    "    'walking': 0.4,\n",
    "    'walking-impaired': 0.2,\n",
    "    'sitting': 900,\n",
    "    'standing': 300,\n",
    "    'stairs-ascending': 0.3,\n",
    "    'stairs-descending': 0.3,\n",
    "    'cycling-50W': 0.3,\n",
    "    'cycling-100W': 0.3,\n",
    "    'default': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/home/lukasadamowicz/Documents/Datasets/processed')\n",
    "\n",
    "datasets = [\n",
    "    base_path / 'bluesky2',\n",
    "    base_path / 'daliac',\n",
    "    base_path / 'ltmm',\n",
    "    base_path / 'usc-had'\n",
    "]\n",
    "\n",
    "X_, Y, subjects, activities = load_datasets(\n",
    "    paths=datasets,\n",
    "    goal_fs=50.0,\n",
    "    window_length=3.0,\n",
    "    window_step=steps,\n",
    "    acc_mag=False,\n",
    "    signal_function=band_filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_nf, _, _, _ = load_datasets(\n",
    "    paths=datasets,\n",
    "    goal_fs=50.0,\n",
    "    window_length=3.0,\n",
    "    window_step=steps,\n",
    "    acc_mag=False,\n",
    "    signal_function=None\n",
    ")\n",
    "\n",
    "x_mn = Mean().compute(x_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros(X_.shape[:-1])\n",
    "for subj in np.unique(subjects):\n",
    "    mask = (subjects == subj) & ((activities == 'walking-impaired') | (activities == 'walking'))\n",
    "    if mask.sum() == 0:\n",
    "        print('no mask')\n",
    "    idx = np.argmax(np.abs(np.sum(x_mn[mask], axis=0)))\n",
    "    \n",
    "    if np.sum(x_mn[mask], axis=0)[idx] < 0:\n",
    "        X[subjects == subj] = X_[subjects == subj, :, idx]\n",
    "    else:\n",
    "        X[subjects == subj] = -1 * X_[subjects == subj, :, idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomize validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "rnd_subjects = [i for i in np.unique(subjects) if np.unique(activities[subjects==i]).size > 3]\n",
    "random.shuffle(rnd_subjects)\n",
    "\n",
    "training_masks, validation_masks, testing_masks = [], [], []\n",
    "\n",
    "for i in range(0, len(rnd_subjects), 4):\n",
    "    trm = np.ones(len(subjects), dtype='bool')\n",
    "    vm = np.zeros_like(trm, dtype='bool')\n",
    "    tem = np.zeros_like(trm, dtype='bool')\n",
    "    \n",
    "    for j in range(4):\n",
    "        trm &= subjects != rnd_subjects[i + j]\n",
    "        if j < 2:\n",
    "            vm |= subjects == rnd_subjects[i + j]\n",
    "        else:\n",
    "            tem |= subjects == rnd_subjects[i + j]\n",
    "    \n",
    "    training_masks.append(trm)\n",
    "    validation_masks.append(vm)\n",
    "    testing_masks.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = Bank(window_length=None, window_step=None)\n",
    "\n",
    "FB + PowerSpectralSum(low_cutoff=0.0, high_cutoff=12.0)\n",
    "FB + DominantFrequencyValue(low_cutoff=0.0, high_cutoff=12.0)\n",
    "FB + MeanCrossRate()\n",
    "FB + Range()\n",
    "FB + RMS()\n",
    "FB + SignalEntropy()\n",
    "FB + SpectralEntropy(low_cutoff=0.0, high_cutoff=12.0)\n",
    "FB + SpectralFlatness(low_cutoff=0.0, high_cutoff=12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat, fnames = FB.compute(X, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.18.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.18.2 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('gaitpy_v1/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame(data=X_feat, columns=fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240260e77b0a478989afcb302aad1ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "sns.boxplot(x='variable', y='value', data=fdf.melt(value_vars=fnames), ax=ax)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance\n",
      "F1:   12.5  TP:    7.1  FP:    5.0\n",
      "F1:    0.0  TP:    0.0  FP:   18.7\n",
      "F1:    3.8  TP:    2.5  FP:   13.6\n",
      "F1:    0.0  TP:    0.0  FP:   25.1\n",
      "F1:   27.4  TP:   16.1  FP:    3.1\n",
      "F1:   14.8  TP:    8.0  FP:    0.9\n",
      "F1:   49.4  TP:   33.5  FP:    1.5\n",
      "F1:    1.5  TP:    0.8  FP:    0.7\n",
      "F1:    0.6  TP:    0.4  FP:   22.0\n",
      "F1:   36.0  TP:   23.1  FP:    2.5\n",
      "F1:    0.0  TP:    0.0  FP:   23.1\n",
      "\n",
      " --------------------------------------------------\n",
      "Mean (SD) F1: 13.3(16.3)\n",
      "Mean (SD) TP: 8.3(10.8)\n",
      "Mean (SD) FP: 10.6(9.5)\n"
     ]
    }
   ],
   "source": [
    "f1, tp, fp = [], [], []\n",
    "\n",
    "print('Validation set performance')\n",
    "for trm, vm, tem in zip(training_masks, validation_masks, testing_masks):\n",
    "    y_pred = model.predict_proba(X_feat[vm])[:, 1]\n",
    "    \n",
    "    # compute metrics\n",
    "    f1.append(f1_score(Y[vm], y_pred > thresh))\n",
    "    tp.append((Y[vm] & (y_pred > thresh)).sum() / Y[vm].sum())\n",
    "    fp.append((~Y[vm].astype(bool) & (y_pred > thresh)).sum() / (Y[vm].size - Y[vm].sum()))\n",
    "    \n",
    "    print(f'F1: {f1[-1]*100:6.1f}', end='')\n",
    "    print(f'  TP: {tp[-1]*100:6.1f}', end='')\n",
    "    print(f'  FP: {fp[-1]*100:6.1f}')\n",
    "    \n",
    "print('\\n', '-' * 50)\n",
    "print(f'Mean (SD) F1: {np.mean(f1)*100:.1f}({np.std(f1)*100:.1f})')\n",
    "print(f'Mean (SD) TP: {np.mean(tp)*100:.1f}({np.std(tp)*100:.1f})')\n",
    "print(f'Mean (SD) FP: {np.mean(fp)*100:.1f}({np.std(fp)*100:.1f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaitpy_v1 import signal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gaitpy_v1/feature_order.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "lines = ['y_' + i.strip('\\n').split('_', 5)[-1] for i in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_dom_freq_ratio</th>\n",
       "      <th>y_dom_freq_value</th>\n",
       "      <th>y_mean_cross_rate</th>\n",
       "      <th>y_range</th>\n",
       "      <th>y_rms</th>\n",
       "      <th>y_signal_entropy</th>\n",
       "      <th>y_spectral_entropy</th>\n",
       "      <th>y_spectral_flatness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.295722</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>1.717011</td>\n",
       "      <td>0.762920</td>\n",
       "      <td>-6.993848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.295889</td>\n",
       "      <td>0.121295</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.004001</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>1.688673</td>\n",
       "      <td>0.765209</td>\n",
       "      <td>-6.937629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_dom_freq_ratio  y_dom_freq_value  y_mean_cross_rate   y_range     y_rms  \\\n",
       "0          0.295722          1.953125           0.126667  0.004001  0.000620   \n",
       "1          0.295889          0.121295           0.126667  0.004001  0.000622   \n",
       "\n",
       "   y_signal_entropy  y_spectral_entropy  y_spectral_flatness  \n",
       "0          1.717011            0.762920            -6.993848  \n",
       "1          1.688673            0.765209            -6.937629  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = 1\n",
    "\n",
    "df = pd.DataFrame(data=X[ix].reshape((-1, 1)), columns=['y'])\n",
    "\n",
    "res = signal_features._signal_features(df, ['y'], 50.0)\n",
    "res = res[lines]\n",
    "res.loc[1, :] = X_feat[ix]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
