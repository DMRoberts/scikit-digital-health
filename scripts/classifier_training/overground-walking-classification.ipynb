{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, precision_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../feature_exploration/features.h5', key='no_preprocessing')\n",
    "feats = data.iloc[:, 3:]\n",
    "labels = data.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sitting', 'standing', 'walking', 'walking-impaired',\n",
       "       'standing-assisted', 'sit-to-stand', 'cycling-100W', 'cycling-50W',\n",
       "       'jumping-rope', 'lying', 'running-treadmill', 'stairs-ascending',\n",
       "       'stairs-descending', 'sweeping', 'vacuuming', 'washing-dishes',\n",
       "       'elevator-ascending', 'elevator-descending', 'jumping', 'running',\n",
       "       'sleeping', 'walking-left', 'walking-right'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Activity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with stairs as positive class\n",
    "data_strs = pd.read_hdf('../feature_exploration/features.h5', key='incl_stairs')\n",
    "feats_strs = data_strs.iloc[:, 3:]\n",
    "labels_strs = data_strs.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the k-fold splits, but on subjects\n",
    "gbc = data.groupby(['Subject', 'Activity'], as_index=False).count()\n",
    "fold_subjects = [i for i in gbc.Subject.unique() if gbc.loc[gbc.Subject == i].shape[0] > 3]\n",
    "\n",
    "random.seed(5)  # fix the generation for repeatability\n",
    "random.shuffle(fold_subjects)\n",
    "\n",
    "trn_m, utrn_m, val_m, tst_m = [], [], [], []\n",
    "n_lo = 4\n",
    "for i in range(0, len(fold_subjects), n_lo):\n",
    "    trn_m.append(np.ones(data.shape[0], dtype='bool'))\n",
    "    utrn_m.append(np.ones(data.shape[0], dtype='bool'))\n",
    "    val_m.append(np.zeros(data.shape[0], dtype='bool'))\n",
    "    tst_m.append(np.zeros(data.shape[0], dtype='bool'))\n",
    "    \n",
    "    for j in range(n_lo):\n",
    "        trn_m[-1] &= (data.Subject != fold_subjects[i+j]).values\n",
    "        utrn_m[-1] &= (data.Subject != fold_subjects[i+j]).values\n",
    "    for j in range(n_lo - (n_lo // 2)):\n",
    "        val_m[-1] |= (data.Subject == fold_subjects[i+j]).values\n",
    "    for j in range(n_lo - (n_lo // 2), n_lo):\n",
    "        tst_m[-1] |= (data.Subject == fold_subjects[i+j]).values\n",
    "    \n",
    "    # make the unary (one-class) classifier mask to be \n",
    "    # only walking activities for the specific subjects\n",
    "    mask = np.zeros(data.shape[0], dtype='bool')\n",
    "    for a in [i for i in data.Activity.unique() if 'walking' in i]:\n",
    "        mask |= (data.Activity == a).values\n",
    "    utrn_m[-1] &= mask\n",
    "\n",
    "cv = tuple(zip(trn_m, val_m))\n",
    "ucv = tuple(zip(utrn_m, val_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uf1_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    y_pred[y_pred == -1] = 0\n",
    "    \n",
    "    return f1_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overground Walking Classification Summary\n",
    "\n",
    "This is a summary of the work-process for classifying overground gait from a lumbar accelerometer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Activity/Class balancing\n",
    "\n",
    "Window length: 3s\n",
    "Overlap: variable\n",
    "Sampling Frequency: 50Hz (downsampled where necessary)\n",
    "\n",
    "Loading data with a constand window for all activities didn't result in a nice distribution of activities, especially those which need to be captured for the classifier to work well, such as running, or stair ascent/descent.\n",
    "\n",
    "In order to provide a better balance of classes, the spacing or overlap between windows was adjust per activity to the following:\n",
    "\n",
    "| Activity             | Overlap |\n",
    "|----------------------|---------|\n",
    "| jumping-rope         | 0.15    |\n",
    "| stairs-descending    | 0.10    |\n",
    "| stairs-ascending     | 0.10    |\n",
    "| jumping              | 0.15    |\n",
    "| lying                | 0.15    |\n",
    "| elevator-ascending   | 0.15    |\n",
    "| elevator-descending  | 0.15    |\n",
    "| running              | 0.075   |\n",
    "| sweeping             | 0.15    |\n",
    "| standing             | 225     |\n",
    "| running-treadmill    | 0.10    |\n",
    "| cycling-50W          | 0.12    |\n",
    "| cycling-100W         | 0.12    |\n",
    "| walking-left         | 0.20    |\n",
    "| walking-right        | 0.20    |\n",
    "| walking-impaired     | 0.20    |\n",
    "| walking              | 0.25    |\n",
    "| sitting              | 400     |\n",
    "| default              | 0.50    |\n",
    "\n",
    "where a float indicates the % overlap between adjacent windows (ie 0.5 would be 50% overlap, or 75 samples between starts), and an integer indicates the number of samples between window starts (so 400 would exclude data of samples 151-400)\n",
    "\n",
    "This results in the following distribution of positive/negative samples (stair ascending/descending in the negative class for now):\n",
    "\n",
    "| Category    | Samples |\n",
    "|-------------|---------|\n",
    "| Total       | 105,029 |\n",
    "| Walking     | 32,781  |\n",
    "| Non-walking | 73,986  |\n",
    "|-------------|---------|\n",
    "| % walking   | 30.70%  |\n",
    "\n",
    "and the following specific activity breakdown:\n",
    "\n",
    "| Activity                 | Samples / Total   | % Samples |\n",
    "|--------------------------|-------------------|-----------|\n",
    "| sit-to-stand             |     30 / 105,029  |  0.00     |\n",
    "| standing-assisted        |    401 / 105,029  |  0.00     |\n",
    "| vacuuming                |    736 / 105,029  |  0.01     |\n",
    "| lying                    |    739 / 105,029  |  0.01     |\n",
    "| jumping-rope             |  1,373 / 105,029  |  0.01     |\n",
    "| washing-dishes           |  1,538 / 105,029  |  0.01     |\n",
    "| jumping                  |  1,869 / 105,029  |  0.02     |\n",
    "| sleeping                 |  2,245 / 105,029  |  0.02     |\n",
    "| elevator-descending      |  3,070 / 105,029  |  0.03     |\n",
    "| elevator-ascending       |  3,119 / 105,029  |  0.03     |\n",
    "| walking-left             |  3,774 / 105,029  |  0.04     |\n",
    "| standing                 |  3,875 / 105,029  |  0.04     |\n",
    "| walking-right            |  4,023 / 105,029  |  0.04     |\n",
    "| sweeping                 |  4,090 / 105,029  |  0.04     |\n",
    "| cycling-50W              |  6,251 / 105,029  |  0.06     |\n",
    "| cycling-100W             |  6,266 / 105,029  |  0.06     |\n",
    "| running                  |  6,764 / 105,029  |  0.06     |\n",
    "| sitting                  |  6,920 / 105,029  |  0.07     |\n",
    "| stairs-descending        |  7,336 / 105,029  |  0.07     |\n",
    "| running-treadmill        |  7,415 / 105,029  |  0.07     |\n",
    "| stairs-ascending         |  8,211 / 105,029  |  0.08     |\n",
    "| walking-impaired         |  8,241 / 105,029  |  0.08     |\n",
    "| walking                  | 16,743 / 105,029  |  0.16     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features were compute on the magnitude of the acceleration, computed per:\n",
    "$$a_{mag} = \\sqrt{a_x^2+a_y^2+a_z^2}$$\n",
    "\n",
    "The following features were computed:\n",
    "\n",
    "| Feature                      | Parameters | \n",
    "|------------------------------|------------|\n",
    "| Mean                         |                                         |\n",
    "| MeanCrossRate                |                                         |\n",
    "| StdDev                       |                                         |\n",
    "| Skewness                     |                                         |\n",
    "| Kurtosis                     |                                         |\n",
    "| Range                        |                                         |\n",
    "| IQR                          |                                         |\n",
    "| RMS                          |                                         |\n",
    "| Autocorrelation              | lag=1, normalize=True                   |\n",
    "| LinearSlope                  |                                         |\n",
    "| SignalEntropy                |                                         |\n",
    "| SampleEntropy                | m=4, r=1.0                              |\n",
    "| PermutationEntropy           | order=3, delay=1, normalize=True        |\n",
    "| ComplexityInvariantDistance  | normalize=True                          |\n",
    "| RangeCountPercentage         | range_min=0, range_max=1.0              |\n",
    "| RatioBeyondRSigma            | r=2.0                                   |\n",
    "| JerkMetric                   | normalize=True                          |\n",
    "| DimensionlessJerk            | log=True, signal_type='acceleration'    |\n",
    "| SPARC                        |                                         |\n",
    "| DominantFrequency            | low_cutoff=0.25, high_cutoff=5.0        |\n",
    "| DominantFrequencyValue       | low_cutoff=0.25, high_cutoff=5.0        |\n",
    "| PowerSpectralSum             | low_cutoff=0.25, high_cutoff=5.0        |\n",
    "| SpectralFlatness             | low_cutoff=0.25, high_cutoff=5.0        |\n",
    "| SpectralEntropy              | low_cutoff=0.25, high_cutoff=5.0        |\n",
    "| DetailPower                  | wavelet='coif4', freq_band=[1.0, 3.0]   |\n",
    "| DetailPowerRatio             | wavelet='coif4', freq_band=[1.0, 3.0]   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>TODO:</b> Explore effect of changing parameters. Could use PPScore to see effect on classification\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Selection\n",
    "\n",
    "Initial testing on binary classifiers SVM/RandomForest/XGBoost and one-class classifiers IsolationForest/OneClassSVM\n",
    "\n",
    "Initial testing was done with stair ascent/descent as the __*negative*__ class\n",
    "\n",
    "Overall performance showed that a binary classifier would achieve higher results. Initially dropping some features showed little/no change in performance, but as features were dropped based on feature performance in the classifiers this isn't surprising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 81.32\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=20)\n",
    "cv_res = cross_val_score(\n",
    "    RF, \n",
    "    feats, \n",
    "    labels, \n",
    "    scoring=make_scorer(f1_score), \n",
    "    cv=cv, \n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Average F1: {np.mean(cv_res)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: SVM\n",
    "SVM takes a while to run\n",
    "\n",
    "Average F1: ~58.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 58.84\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=1.0, kernel='rbf')\n",
    "run = False\n",
    "if run:\n",
    "    cv_res = cross_val_score(\n",
    "        svm, \n",
    "        feats,\n",
    "        labels,\n",
    "        scoring=make_scorer(f1_score),\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f'Average F1: {np.mean(cv_res)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c. XGBoost\n",
    "In the end showed similar performance to the random forest, but has the benefit of faster run times and better persistence/saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 84.01\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "cv_res = cross_val_score(\n",
    "    clf,\n",
    "    feats,\n",
    "    labels,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Average F1: {np.mean(cv_res)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 61.86\n"
     ]
    }
   ],
   "source": [
    "IF = IsolationForest(n_estimators=20)\n",
    "cv_res = cross_val_score(\n",
    "    IF,\n",
    "    feats,\n",
    "    labels,\n",
    "    scoring=uf1_scorer,\n",
    "    cv=ucv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Average F1: {np.mean(cv_res)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e: One-class SVM\n",
    "Also takes a while\n",
    "\n",
    "Average F1: ~48.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 48.52\n"
     ]
    }
   ],
   "source": [
    "usvc = OneClassSVM(kernel='rbf')\n",
    "run = False\n",
    "if run:\n",
    "    cv_res = cross_val_score(\n",
    "        usvc,\n",
    "        feats,\n",
    "        labels,\n",
    "        scoring=uf1_scorer,\n",
    "        cv=ucv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f'Average F1: {np.mean(cv_res)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the large number of classes, it isn't surprising that the binary classifiers end up working better, given that they should be able to account for the feature space occupied by the other activities better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stair ascent/descent\n",
    "\n",
    "The most confusion in the training results from the stair ascent/descent tasks, which is intuitive give that they are the most similar to walking, especially when using acceleration magnitude. Therefore, some tests including stairs in the positive class showed that the performance jumped about 10 points, up to $~93\\%$.  \n",
    "\n",
    "The intent with lumping them together was to have cascaded models where another classifier, or DSP model would differentiate between normal overground walking and stair climbing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1f: XGBoost with stairs as positive class\n",
    "\n",
    "From $~84\\%$ to $~94\\%$ with the inclusion of stairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1: 94.65\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "cv_res = cross_val_score(\n",
    "    clf,\n",
    "    feats_strs,\n",
    "    labels_strs,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f'Average F1: {np.mean(cv_res)*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lazypredict\n",
    "\n",
    "Next, I tried lazypredict, a python package that runs a bunch of classifiers without any optimization. It ran on 1 fold of the training/validation data, generating the below results:\n",
    "\n",
    "![lazypredict fold 1 results](lazypredict_results.png \"lazypredict results for first fold\")\n",
    "\n",
    "Looking at the results, not only did LightGBM work the best (only for one fold, but still), it is also quite fast. I did some testing, and the results are certainly no worse than other models, and might be slightly better, with very fast training/prediction times as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameter selection\n",
    "\n",
    "With several promising models, further testing was on which model features yeilded the best results. This search was done using the scikit-learn RandomizedSearchCV, overal several of the prominent parameters for each of the models chosen:\n",
    "\n",
    "- RandomForest\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "note that the *mean_test_score* in the RFC results is accuracy, not F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.941335</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.940712</td>\n",
       "      <td>gini</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.939920</td>\n",
       "      <td>gini</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.939771</td>\n",
       "      <td>gini</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.939560</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score param_criterion  param_max_depth  param_min_samples_leaf  \\\n",
       "40         0.941335            gini              NaN                       4   \n",
       "8          0.940712            gini             16.0                       1   \n",
       "13         0.939920            gini             16.0                       2   \n",
       "69         0.939771            gini             16.0                       1   \n",
       "70         0.939560            gini              NaN                       1   \n",
       "\n",
       "    param_min_samples_split  param_n_estimators  \n",
       "40                       20                  22  \n",
       "8                        20                  25  \n",
       "13                        2                  99  \n",
       "69                       20                  47  \n",
       "70                      100                  51  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_rscv = pd.read_csv('rfc_cv_results_incl_stairs.csv', index_col=0)\n",
    "cols = ['mean_test_score'] + [i for i in rfc_rscv.columns if 'param_' in i]\n",
    "rfc_rscv.sort_values('rank_test_score').loc[:, cols].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_importance_type</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_tree_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.937247</td>\n",
       "      <td>1.00</td>\n",
       "      <td>gain</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.936439</td>\n",
       "      <td>0.00</td>\n",
       "      <td>weight</td>\n",
       "      <td>0.029959</td>\n",
       "      <td>12</td>\n",
       "      <td>61</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>exact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.936391</td>\n",
       "      <td>0.01</td>\n",
       "      <td>weight</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>12</td>\n",
       "      <td>73</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.935336</td>\n",
       "      <td>0.01</td>\n",
       "      <td>weight</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>11</td>\n",
       "      <td>96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.935229</td>\n",
       "      <td>1.00</td>\n",
       "      <td>gain</td>\n",
       "      <td>0.231022</td>\n",
       "      <td>10</td>\n",
       "      <td>59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_F1  param_gamma param_importance_type  param_learning_rate  \\\n",
       "62      0.937247         1.00                  gain             0.002833   \n",
       "29      0.936439         0.00                weight             0.029959   \n",
       "77      0.936391         0.01                weight             0.000015   \n",
       "85      0.935336         0.01                weight             0.003325   \n",
       "2       0.935229         1.00                  gain             0.231022   \n",
       "\n",
       "    param_max_depth  param_n_estimators  param_reg_alpha  param_reg_lambda  \\\n",
       "62               10                  67             1.25               2.0   \n",
       "29               12                  61             1.00               0.1   \n",
       "77               12                  73             1.00               2.0   \n",
       "85               11                  96             1.00               1.0   \n",
       "2                10                  59             1.00               2.0   \n",
       "\n",
       "   param_tree_method  \n",
       "62              hist  \n",
       "29             exact  \n",
       "77              hist  \n",
       "85              hist  \n",
       "2               hist  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_rscv = pd.read_csv('xgbrf_cv_results_incl_stairs.csv')\n",
    "cols = ['mean_test_F1'] + [i for i in xgb_rscv.columns if 'param_' in i]\n",
    "xgb_rscv.sort_values('rank_test_F1').loc[:, cols].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>param_boosting_type</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_num_leaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.946718</td>\n",
       "      <td>goss</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>125</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.944939</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21</td>\n",
       "      <td>125</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.944558</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.2</td>\n",
       "      <td>14</td>\n",
       "      <td>125</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.944139</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1</td>\n",
       "      <td>125</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.944088</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21</td>\n",
       "      <td>125</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_F1 param_boosting_type  param_learning_rate  param_max_depth  \\\n",
       "179      0.946718                goss                  0.2                7   \n",
       "126      0.944939                dart                  0.3               21   \n",
       "108      0.944558                dart                  0.2               14   \n",
       "127      0.944139                dart                  0.3               -1   \n",
       "199      0.944088                dart                  0.3               21   \n",
       "\n",
       "     param_n_estimators  param_num_leaves  \n",
       "179                 125                41  \n",
       "126                 125                31  \n",
       "108                 125                29  \n",
       "127                 125                26  \n",
       "199                 125                30  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_rscv = pd.read_csv('lgb_cv_results_incl_stairs.csv')\n",
    "cols = ['mean_test_F1'] + [i for i in lgb_rscv.columns if 'param_' in i]\n",
    "lgb_rscv.sort_values('rank_test_F1').loc[:, cols].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a miniscule advantage gained from using the picked parameters, only the learning rate was taken moving forward, as the performance of the default parameters is almost exactly the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of estimators\n",
    "\n",
    "With LightGBM doing well (and its speed), the following is moving fowards with the __LightGBM being the classifier of choice__\n",
    "\n",
    "While the RandomizedSearchCV showed that the number of estimators was best at 125, there is still a tradeoff, which should be analyzed, not only for speed but for storage space when the final model needs to be saved.\n",
    "\n",
    "The results of testing number of estimators is shown in the below graph (parameters: *learning_rate=0.2*):\n",
    "\n",
    "![# estimator testing](gait_classifier/lightgbm_n-estimators_performance.png \"Number of Estimator performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that performance does keep increasing as estimators are added, but also that 75 estimators results in essentially equivalent performance, and the % change in score drops off for the most part after this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Elimination\n",
    "\n",
    "Next, testing on which/whether or not features could be removed from the model, while maintaining sufficient performance.\n",
    "\n",
    "Using the Recursive Feature Elimination CV from sklearn, on both the LightGBM model, and a single Decision Tree, similar results were obtained - essentially all of the features are necessary to maintain performance:\n",
    "\n",
    "![RFECV results](gait_classifier/RFECV_results.png \"RFECV results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Parameters\n",
    "\n",
    "At this point, since several of the features have adjustable parameters (and while most of them seemed to be based on optimal/original paper values, this is not guarantee), the importance of adjusting these parameters was explored.  This first step was using Predictive Power Score to assess which features independently had the best performance towards classifying gait.\n",
    "\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/autocorrelation.png\" alt=\"Autocorrelation\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/sample_entropy.png\" alt=\"Sample Entropy\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/permutation_entropy.png\" alt=\"Permutation Entropy\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/range_count_percentage.png\" alt=\"Range Count Percentage\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/ratio_beyond_r_sigma.png\" alt=\"Ratio Beyond R Sigma\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/dominant_frequency.png\" alt=\"Dominant Frequency\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/power_spectral_sum.png\" alt=\"Power Spectral Sum\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/spectral_entropy.png\" alt=\"Spectral Entropy\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/spectral_flatness.png\" alt=\"Spectral Flatness\" width=\"600\"/>\n",
    "<img src=\"../feature_exploration/feature_parameter_pps/detail_power_ratio.png\" alt=\"Detail Power Ratio\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the above testing, did more testing of the LightGBM classifier with the parameters that looked more promising, and started exploring stairs back in the negative class again. The class distribution was also tweaked so that the positive and negative classes were more closely balanced, to the below distribution, that also overall has less overlap between windows:\n",
    "\n",
    "| Activity             | Overlap |\n",
    "|----------------------|---------|\n",
    "| walking              | 0.40    |\n",
    "| walking-impaired     | 0.20    |\n",
    "| sitting              | 900     |\n",
    "| standing             | 300     |\n",
    "| stairs-ascending     | 0.30    |\n",
    "| stairs-descending    | 0.30    |\n",
    "| cycling-50W          | 0.30    |\n",
    "| cycling-100W         | 0.30    |\n",
    "| default              | 1.00    |\n",
    "\n",
    "\n",
    "| Category    | Samples |\n",
    "|-------------|---------|\n",
    "| Total       | 43,163  |\n",
    "| Walking     | 20,581  |\n",
    "| Non-walking | 22,645  |\n",
    "|-------------|---------|\n",
    "| % walking   | 47.54%  |\n",
    "\n",
    "and the following specific activity breakdown:\n",
    "\n",
    "| Activity                 | Samples / Total  | % Samples |\n",
    "|--------------------------|------------------|-----------|\n",
    "| sit-to-stand             |     16 / 43,163  |  0.00     |\n",
    "| standing-assisted        |    207 / 43,163  |  0.00     |\n",
    "| jumping-rope             |    212 / 43,163  |  0.00     |\n",
    "| vacuuming                |    311 / 43,163  |  0.01     |\n",
    "| lying                    |    376 / 43,163  |  0.01     |\n",
    "| elevator-descending      |    378 / 43,163  |  0.01     |\n",
    "| elevator-ascending       |    475 / 43,163  |  0.01     |\n",
    "| washing-dishes           |    491 / 43,163  |  0.01     |\n",
    "| running                  |    541 / 43,163  |  0.01     |\n",
    "| sweeping                 |    612 / 43,163  |  0.01     |\n",
    "| running-treadmill        |    755 / 43,163  |  0.02     |\n",
    "| washing-dishes           |    776 / 43,163  |  0.02     |\n",
    "| walking-left             |    787 / 43,163  |  0.02     |\n",
    "| walking-right            |    842 / 43,163  |  0.02     |\n",
    "| sleeping                 |  1,126 / 43,163  |  0.03     |\n",
    "| stairs-descending        |  2,477 / 43,163  |  0.06     |\n",
    "| cycling-50W              |  2,509 / 43,163  |  0.06     |\n",
    "| cycling-100W             |  2,515 / 43,163  |  0.06     |\n",
    "| stairs-ascending         |  2,763 / 43,163  |  0.06     |\n",
    "| standing                 |  2,953 / 43,163  |  0.07     |\n",
    "| sitting                  |  3,152 / 43,163  |  0.07     |\n",
    "| walking-impaired         |  8,241 / 43,163  |  0.19     |\n",
    "| walking                  | 10,648 / 43,163  |  0.25     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test against GaitPy existing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
