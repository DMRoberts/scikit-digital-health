{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from PfyMU.gait.train_classifier.core import load_datasets\n",
    "from PfyMU.features import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_band_filter(x, fs):\n",
    "    sos = butter(\n",
    "        1, \n",
    "        [2 * 0.25 / fs, 2 * 5 / fs], \n",
    "        btype='band', \n",
    "        output='sos'\n",
    "    )\n",
    "    \n",
    "    return sosfiltfilt(sos, np.linalg.norm(x, axis=1))\n",
    "\n",
    "steps = {\n",
    "    'walking': 0.4,\n",
    "    'walking-impaired': 0.2,\n",
    "    'sitting': 900,\n",
    "    'standing': 300,\n",
    "    'stairs-ascending': 0.3,\n",
    "    'stairs-descending': 0.3,\n",
    "    'cycling-50W': 0.3,\n",
    "    'cycling-100W': 0.3,\n",
    "    'default': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('/home/lukasadamowicz/Documents/Datasets/processed')\n",
    "\n",
    "datasets = [\n",
    "    base_path / 'bluesky2',\n",
    "    base_path / 'daliac',\n",
    "    base_path / 'ltmm',\n",
    "    base_path / 'usc-had'\n",
    "]\n",
    "\n",
    "X, Y, subjects, activities = load_datasets(\n",
    "    paths=datasets,\n",
    "    goal_fs=50.0,\n",
    "    window_length=3.0,\n",
    "    window_step=steps,\n",
    "    acc_mag=False,\n",
    "    signal_function=mag_band_filter\n",
    ")\n",
    "\n",
    "Y2 = Y.copy()\n",
    "Y2[['stair' in i for i in activities]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomize validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "rnd_subjects = [i for i in np.unique(subjects) if np.unique(activities[subjects==i]).size > 3]\n",
    "random.shuffle(rnd_subjects)\n",
    "\n",
    "training_masks, validation_masks, testing_masks = [], [], []\n",
    "\n",
    "for i in range(0, len(rnd_subjects), 4):\n",
    "    trm = np.ones(len(subjects), dtype='bool')\n",
    "    vm = np.zeros_like(trm, dtype='bool')\n",
    "    tem = np.zeros_like(trm, dtype='bool')\n",
    "    \n",
    "    for j in range(4):\n",
    "        trm &= subjects != rnd_subjects[i + j]\n",
    "        if j < 2:\n",
    "            vm |= subjects == rnd_subjects[i + j]\n",
    "        else:\n",
    "            tem |= subjects == rnd_subjects[i + j]\n",
    "    \n",
    "    training_masks.append(trm)\n",
    "    validation_masks.append(vm)\n",
    "    testing_masks.append(tem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = Bank(window_length=None, window_step=None)\n",
    "\n",
    "FB.load('final_features.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat, fnames = FB.compute(X, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "with open('final_lgb_params.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.strip('\\n').split(':')\n",
    "\n",
    "        if '.' in parts[1]:\n",
    "            best_params[parts[0]] = float(parts[1])\n",
    "        elif parts[1].isnumeric():\n",
    "            best_params[parts[0]] = int(parts[1])\n",
    "        else:\n",
    "            best_params[parts[0]] = parts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance\n",
      "F1:   95.5      99.5  TP:   94.1      99.7  FP:    2.1       0.6\n",
      "F1:   92.5      97.7  TP:   95.9     100.0  FP:    4.2       2.9\n",
      "F1:   93.0      96.3  TP:   93.1      96.4  FP:    3.1       2.4\n",
      "F1:   91.6      97.4  TP:   97.6     100.0  FP:    5.4       3.3\n",
      "F1:   82.9      81.2  TP:   71.5      69.0  FP:    2.4       2.1\n",
      "F1:   94.7      97.5  TP:   90.3      95.6  FP:    0.6       0.9\n",
      "F1:   88.3      97.6  TP:   80.2      95.5  FP:    1.0       0.4\n",
      "F1:   94.3      99.0  TP:   95.4      98.2  FP:    7.3       0.4\n",
      "F1:   94.2      97.0  TP:   97.0      98.0  FP:    5.1       3.8\n",
      "F1:   93.5      98.7  TP:   94.8      98.3  FP:    3.5       2.1\n",
      "F1:   80.2      95.5  TP:   75.2     100.0  FP:    5.3       6.9\n",
      "\n",
      " --------------------------------------------------\n",
      "Mean (SD) F1: 91.0(4.8)   96.1(4.8)\n",
      "Mean (SD) TP: 89.5(8.9)   95.5(8.6)\n",
      "Mean (SD) FP: 3.7(2.0)   2.3(1.8)\n"
     ]
    }
   ],
   "source": [
    "f1, f1_2 = [], []\n",
    "tp, tp2 = [], []\n",
    "fp, fp2 = [], []\n",
    "\n",
    "print('Validation set performance')\n",
    "for trm, vm, tem in zip(training_masks, validation_masks, testing_masks):\n",
    "    lgb_cls = lgb.LGBMClassifier(**best_params)\n",
    "    lgb_cls2 = lgb.LGBMClassifier(**best_params)\n",
    "    \n",
    "    lgb_cls.fit(X_feat[trm], Y[trm])\n",
    "    lgb_cls2.fit(X_feat[trm], Y2[trm])\n",
    "    \n",
    "    y_pred = lgb_cls.predict_proba(X_feat[vm])[:, 1]\n",
    "    y2_pred = lgb_cls2.predict_proba(X_feat[vm])[:, 1]\n",
    "    \n",
    "    # compute metrics\n",
    "    f1.append(f1_score(Y[vm], y_pred > thresh))\n",
    "    f1_2.append(f1_score(Y2[vm], y2_pred > thresh))\n",
    "    tp.append((Y[vm] & (y_pred > thresh)).sum() / Y[vm].sum())\n",
    "    tp2.append((Y2[vm] & (y2_pred > thresh)).sum() / Y2[vm].sum())\n",
    "    fp.append((~Y[vm].astype(bool) & (y_pred > thresh)).sum() / (Y[vm].size - Y[vm].sum()))\n",
    "    fp2.append((~Y2[vm].astype(bool) & (y2_pred > thresh)).sum() / (Y2[vm].size - Y2[vm].sum()))\n",
    "    \n",
    "    print(f'F1: {f1[-1]*100:6.1f}{f1_2[-1]*100:10.1f}', end='')\n",
    "    print(f'  TP: {tp[-1]*100:6.1f}{tp2[-1]*100:10.1f}', end='')\n",
    "    print(f'  FP: {fp[-1]*100:6.1f}{fp2[-1]*100:10.1f}')\n",
    "    \n",
    "print('\\n', '-' * 50)\n",
    "print(f'Mean (SD) F1: {np.mean(f1)*100:.1f}({np.std(f1)*100:.1f})   {np.mean(f1_2)*100:.1f}({np.std(f1_2)*100:.1f})')\n",
    "print(f'Mean (SD) TP: {np.mean(tp)*100:.1f}({np.std(tp)*100:.1f})   {np.mean(tp2)*100:.1f}({np.std(tp2)*100:.1f})')\n",
    "print(f'Mean (SD) FP: {np.mean(fp)*100:.1f}({np.std(fp)*100:.1f})   {np.mean(fp2)*100:.1f}({np.std(fp2)*100:.1f})')\n",
    "\n",
    "df = pd.DataFrame(columns=['Model', 'Metric', 'Score'])\n",
    "df['Metric'] = ['F1'] * len(f1) + ['TP'] * len(tp) + ['FP'] * len(fp)\n",
    "df['Score'] = f1 + tp + fp\n",
    "df['Model'] = 'V2'\n",
    "\n",
    "df.to_csv('v2_validation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set performance\n",
      "F1:   91.2      95.3  TP:   87.1      91.5  FP:    4.0       0.6\n",
      "F1:   86.1      96.8  TP:   89.4      98.7  FP:    7.4       3.5\n",
      "F1:   91.1      95.5  TP:   85.3      97.2  FP:    1.6      10.0\n",
      "F1:   87.1      98.7  TP:   87.0      97.7  FP:    7.9       0.5\n",
      "F1:   84.8      95.9  TP:   96.4      99.6  FP:   13.6      12.7\n",
      "F1:   73.0      89.3  TP:   60.6      80.8  FP:    3.7       0.7\n",
      "F1:   91.1      99.2  TP:   85.8      99.6  FP:    1.7       1.5\n",
      "F1:   88.6      96.5  TP:   88.8      96.6  FP:    3.7       2.1\n",
      "F1:   60.3      60.2  TP:   45.0      44.9  FP:    5.4       5.4\n",
      "F1:   97.3      98.6  TP:   96.1      98.0  FP:    1.6       1.3\n",
      "F1:   92.5      99.0  TP:   91.9     100.0  FP:    3.3       1.6\n",
      "\n",
      " --------------------------------------------------\n",
      "Mean (SD) F1: 85.7(9.9)   93.2(10.8)\n",
      "Mean (SD) TP: 83.0(15.1)   91.3(15.6)\n",
      "Mean (SD) FP: 4.9(3.4)   3.6(3.9)\n"
     ]
    }
   ],
   "source": [
    "f1, f1_2 = [], []\n",
    "tp, tp2 = [], []\n",
    "fp, fp2 = [], []\n",
    "\n",
    "print('Test set performance')\n",
    "for trm, vm, tem in zip(training_masks, validation_masks, testing_masks):\n",
    "    lgb_cls = lgb.LGBMClassifier(n_estimators=125, **best_params)\n",
    "    lgb_cls2 = lgb.LGBMClassifier(n_estimators=125, **best_params)\n",
    "    \n",
    "    lgb_cls.fit(X_feat[trm], Y[trm])\n",
    "    lgb_cls2.fit(X_feat[trm], Y2[trm])\n",
    "    \n",
    "    y_pred = lgb_cls.predict_proba(X_feat[tem])[:, 1]\n",
    "    y2_pred = lgb_cls2.predict_proba(X_feat[tem])[:, 1]\n",
    "    \n",
    "    y_true = Y[tem].astype(bool)\n",
    "    y2_true = Y2[tem].astype(bool)\n",
    "    \n",
    "    # compute metrics\n",
    "    f1.append(f1_score(y_true, y_pred > thresh))\n",
    "    f1_2.append(f1_score(y2_true, y2_pred > thresh))\n",
    "    tp.append((y_true & (y_pred > thresh)).sum() / y_true.sum())\n",
    "    tp2.append((y2_true & (y2_pred > thresh)).sum() / y2_true.sum())\n",
    "    fp.append((~y_true & (y_pred > thresh)).sum() / (y_true.size - y_true.sum()))\n",
    "    fp2.append((~y2_true & (y2_pred > thresh)).sum() / (y2_true.size - y2_true.sum()))\n",
    "    \n",
    "    print(f'F1: {f1[-1]*100:6.1f}{f1_2[-1]*100:10.1f}', end='')\n",
    "    print(f'  TP: {tp[-1]*100:6.1f}{tp2[-1]*100:10.1f}', end='')\n",
    "    print(f'  FP: {fp[-1]*100:6.1f}{fp2[-1]*100:10.1f}')\n",
    "    \n",
    "print('\\n', '-' * 50)\n",
    "print(f'Mean (SD) F1: {np.mean(f1)*100:.1f}({np.std(f1)*100:.1f})   {np.mean(f1_2)*100:.1f}({np.std(f1_2)*100:.1f})')\n",
    "print(f'Mean (SD) TP: {np.mean(tp)*100:.1f}({np.std(tp)*100:.1f})   {np.mean(tp2)*100:.1f}({np.std(tp2)*100:.1f})')\n",
    "print(f'Mean (SD) FP: {np.mean(fp)*100:.1f}({np.std(fp)*100:.1f})   {np.mean(fp2)*100:.1f}({np.std(fp2)*100:.1f})')\n",
    "\n",
    "df = pd.DataFrame(columns=['Model', 'Metric', 'Score'])\n",
    "df['Metric'] = ['F1'] * len(f1) + ['TP'] * len(tp) + ['FP'] * len(fp)\n",
    "df['Score'] = f1 + tp + fp\n",
    "df['Model'] = 'V2'\n",
    "\n",
    "df.to_csv('v2_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:   95.4  TP:   93.9  FP:    2.1\n",
      "F1:   92.3  TP:   95.9  FP:    4.4\n",
      "F1:   93.2  TP:   93.6  FP:    3.2\n",
      "F1:   91.8  TP:   97.8  FP:    5.4\n",
      "F1:   82.4  TP:   70.7  FP:    2.4\n",
      "F1:   94.9  TP:   90.6  FP:    0.6\n",
      "F1:   88.1  TP:   79.9  FP:    1.0\n",
      "F1:   94.5  TP:   95.6  FP:    7.1\n",
      "F1:   94.3  TP:   97.0  FP:    4.9\n",
      "F1:   93.5  TP:   94.8  FP:    3.5\n",
      "F1:   80.2  TP:   75.4  FP:    5.5\n",
      "\n",
      " --------------------------------------------------\n",
      "Mean (SD) F1: 91.0(5.0)\n",
      "Mean (SD) TP: 89.6(9.1)\n",
      "Mean (SD) FP: 3.7(1.9)\n"
     ]
    }
   ],
   "source": [
    "f1, tp, fp = [], [], []\n",
    "params = best_params.copy()\n",
    "params['n_estimators'] = 125\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['subsample_for_bin'] = 200000\n",
    "params['subsample'] = 1.0\n",
    "params['subsample_freq'] = 0\n",
    "params['colsample_bytree'] = 1.0\n",
    "params['objective'] = 'binary'\n",
    "params['metrics'] = ['binary']\n",
    "\n",
    "print('Validation set performance')\n",
    "for trm, vm, tem in zip(training_masks, validation_masks, testing_masks):\n",
    "    x_dst = lgb.Dataset(X_feat[trm], label=Y[trm])\n",
    "    bst = lgb.train(params, x_dst, num_boost_round=100)\n",
    "    \n",
    "    y_pred = bst.predict(X_feat[vm])\n",
    "    \n",
    "    # compute metrics\n",
    "    f1.append(f1_score(Y[vm], y_pred > thresh))\n",
    "    tp.append((Y[vm] & (y_pred > thresh)).sum() / Y[vm].sum())\n",
    "    fp.append((~Y[vm].astype(bool) & (y_pred > thresh)).sum() / (Y[vm].size - Y[vm].sum()))\n",
    "    \n",
    "    print(f'F1: {f1[-1]*100:6.1f}', end='')\n",
    "    print(f'  TP: {tp[-1]*100:6.1f}', end='')\n",
    "    print(f'  FP: {fp[-1]*100:6.1f}')\n",
    "    \n",
    "print('\\n', '-' * 50)\n",
    "print(f'Mean (SD) F1: {np.mean(f1)*100:.1f}({np.std(f1)*100:.1f})')\n",
    "print(f'Mean (SD) TP: {np.mean(tp)*100:.1f}({np.std(tp)*100:.1f})')\n",
    "print(f'Mean (SD) FP: {np.mean(fp)*100:.1f}({np.std(fp)*100:.1f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f5a923e06d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = best_params.copy()\n",
    "params['n_estimators'] = 125\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['subsample_for_bin'] = 200000\n",
    "params['subsample'] = 1.0\n",
    "params['subsample_freq'] = 0\n",
    "params['colsample_bytree'] = 1.0\n",
    "params['objective'] = 'binary'\n",
    "params['metrics'] = ['binary']\n",
    "\n",
    "\n",
    "x_dst = lgb.Dataset(X_feat, label=Y)\n",
    "bst = lgb.train(params, x_dst, num_boost_round=100)\n",
    "\n",
    "bst.save_model('lgbm_gait_classifier_no-stairs.lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
