{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random # shuffle the subjects\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSO_runner(data, model, train_masks, validate_masks, test_masks, test=False):    \n",
    "    # seperate the features out\n",
    "    feats = data.drop(['Subject', 'Activity', 'Label'], axis=1)\n",
    "    \n",
    "    # metrics\n",
    "    accu = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    \n",
    "    # return the models\n",
    "    mdls = []\n",
    "    \n",
    "    # iterate over groups of N_lo subjects to leave out\n",
    "    if test:\n",
    "        itr = zip(train_masks, test_masks)\n",
    "    else:\n",
    "        itr = zip(train_masks, validate_masks)\n",
    "    for train_mask, pred_mask in itr:\n",
    "        clm = clone(model)\n",
    "        clm.fit(feats.loc[train_mask], data.Label[train_mask])\n",
    "        \n",
    "        y_pred = clm.predict(feats.loc[pred_mask])\n",
    "        y_true = data.Label[pred_mask]\n",
    "        \n",
    "        accu.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "        prec.append(precision_score(y_true, y_pred))\n",
    "        rec.append(recall_score(y_true, y_pred))\n",
    "        f1.append(f1_score(y_true, y_pred))\n",
    "        \n",
    "        mdls.append(clm)\n",
    "    \n",
    "    print(f'Average Accuracy: {np.mean(accu):.2f} ({np.std(accu):.2f})')\n",
    "    print(f'Average Precision: {np.mean(prec):.2f} ({np.std(prec):.2f})')\n",
    "    print(f'Average Recall: {np.mean(rec):.2f} ({np.std(rec):.2f})')\n",
    "    print(f'Average F1 Score: {np.mean(f1):.2f} ({np.std(f1):.2f})')\n",
    "        \n",
    "    return mdls, feats.columns, accu, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_LOSO_runner(data, train_masks, validate_masks, test_masks, test=False):\n",
    "    feats = data.drop(['Subject', 'Activity', 'Label'], axis=1)\n",
    "    labels = data.Label\n",
    "    \n",
    "    # metrics\n",
    "    accu = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    \n",
    "    # return the models\n",
    "    mdls = []\n",
    "    \n",
    "    # iterate over groups of N_lo subjects to leave out    \n",
    "    for train_mask, val_mask, test_mask in zip(train_masks, validate_masks, test_masks):\n",
    "        dtrain = xgb.DMatrix(feats.loc[train_mask], label=labels.loc[train_mask])\n",
    "        dval = xgb.DMatrix(feats.loc[val_mask], label=labels.loc[val_mask])\n",
    "        if test:\n",
    "            dtest = xgb.DMatrix(feats.loc[test_mask], label=labels.loc[test_mask])\n",
    "\n",
    "        params = {\n",
    "            'max_depth': 8,  # default\n",
    "            'eval_metric': ['rmse', 'auc']\n",
    "        }\n",
    "        eval_list = [(dval, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "        bst = xgb.train(params, dtrain, 10, eval_list, verbose_eval=False)\n",
    "        \n",
    "        if test:\n",
    "            y_pred = bst.predict(dtest) > 0.5\n",
    "            y_true = labels.loc[test_mask]\n",
    "        else:\n",
    "            y_pred = bst.predict(dval) > 0.5\n",
    "            y_true = labels.loc[val_mask]\n",
    "        \n",
    "        accu.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "        prec.append(precision_score(y_true, y_pred))\n",
    "        rec.append(recall_score(y_true, y_pred))\n",
    "        f1.append(f1_score(y_true, y_pred))\n",
    "        \n",
    "        mdls.append(bst)\n",
    "        \n",
    "    print(f'Average Accuracy: {np.mean(accu):.2f} ({np.std(accu):.2f})')\n",
    "    print(f'Average Precision: {np.mean(prec):.2f} ({np.std(prec):.2f})')\n",
    "    print(f'Average Recall: {np.mean(rec):.2f} ({np.std(rec):.2f})')\n",
    "    print(f'Average F1 Score: {np.mean(f1):.2f} ({np.std(f1):.2f})')\n",
    "        \n",
    "    return mdls, feats.columns, accu, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unary_LOSO_runner(data, model, train_masks, validate_masks, test_masks, test=False):\n",
    "    feats = data.drop(['Subject', 'Activity', 'Label'], axis=1)\n",
    "    labels = data.Label\n",
    "    \n",
    "    # metrics\n",
    "    accu = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    \n",
    "    # return the models\n",
    "    mdls = []\n",
    "    \n",
    "    # iterate over groups of N_lo subjects to leave out    \n",
    "    if test:\n",
    "        itr = zip(train_masks, test_masks)\n",
    "    else:\n",
    "        itr = zip(train_masks, validate_masks)\n",
    "    for train_mask, pred_mask in itr:\n",
    "        clm = clone(model)\n",
    "        clm.fit(feats.loc[train_mask & (labels == 1)])\n",
    "        \n",
    "        y_pred = clm.predict(feats.loc[pred_mask])\n",
    "        y_pred[y_pred == -1] = 0\n",
    "        y_true = data.Label[pred_mask]\n",
    "        \n",
    "        accu.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "        prec.append(precision_score(y_true, y_pred))\n",
    "        rec.append(recall_score(y_true, y_pred))\n",
    "        f1.append(f1_score(y_true, y_pred))\n",
    "        \n",
    "        mdls.append(clm)\n",
    "        \n",
    "    print(f'Average Accuracy: {np.mean(accu):.2f} ({np.std(accu):.2f})')\n",
    "    print(f'Average Precision: {np.mean(prec):.2f} ({np.std(prec):.2f})')\n",
    "    print(f'Average Recall: {np.mean(rec):.2f} ({np.std(rec):.2f})')\n",
    "    print(f'Average F1 Score: {np.mean(f1):.2f} ({np.std(f1):.2f})')\n",
    "        \n",
    "    return mdls, feats.columns, accu, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_RF_feature_importances(models, features):\n",
    "    ft_impt = pd.DataFrame(columns=['Feature', 'Importance'])\n",
    "    ft_impt['Importance'] = [i for L in models for i in L.feature_importances_]\n",
    "    ft_impt['Feature'] = np.tile(features, len(models))\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.violinplot(x='Feature', y='Importance', data=ft_impt, ax=ax, width=1, scale='width', bw=0.25)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xgb_feature_gains(models):\n",
    "    df = pd.DataFrame(columns=['Feature', 'Split', 'Gain'])\n",
    "    \n",
    "    df['Feature'] = [i for d in models for i in d.get_score(importance_type='gain')]\n",
    "    df['Split'] = np.repeat(np.arange(len(models)), len(models[0].get_score()))\n",
    "    df['Gain'] = [i for d in models for i in d.get_score(importance_type='gain').values()]\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.boxplot(x='Feature', y='Gain', data=df)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../feature_exploration/features.h5', key='no_preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the subjects for which LOSO actually makes sense: those with multiple activities (ie more than just walking)\n",
    "gbc = data.groupby(['Subject', 'Activity'], as_index=False).count()\n",
    "loso_subjects = [i for i in gbc.Subject.unique() if gbc.loc[gbc.Subject == i].shape[0] > 3]\n",
    "\n",
    "random.seed(5)  # fix the generation so that its the same every time\n",
    "random.shuffle(loso_subjects)\n",
    "\n",
    "training_masks = []\n",
    "validation_masks = []\n",
    "testing_masks = []\n",
    "\n",
    "for i in range(0, len(loso_subjects), 3):\n",
    "    tr_m = np.ones(data.shape[0], dtype='bool')\n",
    "    v_m = np.zeros(data.shape[0], dtype='bool')\n",
    "    \n",
    "    for j in range(3):\n",
    "        tr_m &= data.Subject != loso_subjects[i+j]\n",
    "    for j in range(2):\n",
    "        v_m |= data.Subject == loso_subjects[i+j]\n",
    "    te_m = data.Subject == loso_subjects[i+2]\n",
    "    \n",
    "    training_masks.append(tr_m)\n",
    "    validation_masks.append(v_m)\n",
    "    testing_masks.append(te_m)\n",
    "\n",
    "masks = (training_masks, validation_masks, testing_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain expert feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data = data.drop([\n",
    "    'Mean',\n",
    "    'Skewness',\n",
    "    'Kurtosis',\n",
    "    'RMS',\n",
    "    'LinearSlope',\n",
    "    'ComplexityInvariantDistance',\n",
    "    'RangeCountPercentage',\n",
    "    'RatioBeyondRSigma',\n",
    "    'JerkMetric',\n",
    "    'DominantFrequencyValue',\n",
    "    'DetailPower',\n",
    "    'SignalEntropy',\n",
    "    'SpectralFlatness'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_data = data.copy()\n",
    "rs_data.iloc[:, 3:] = RobustScaler().fit_transform(data.iloc[:, 3:])\n",
    "ss_data = data.copy()\n",
    "ss_data.iloc[:, 3:] = StandardScaler().fit_transform(data.iloc[:, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca_data = data.iloc[:, :3].copy()\n",
    "pca_data = pca_data.merge(pd.DataFrame(pca.fit_transform(rs_data.iloc[:, 3:])), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.84 (0.09)\n",
      "Average Recall: 0.81 (0.15)\n",
      "Average F1 Score: 0.81 (0.10)\n",
      "\n",
      "Robust Scaling\n",
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.85 (0.09)\n",
      "Average Recall: 0.81 (0.14)\n",
      "Average F1 Score: 0.82 (0.09)\n",
      "\n",
      "Standard Scaling\n",
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.85 (0.09)\n",
      "Average Recall: 0.81 (0.15)\n",
      "Average F1 Score: 0.82 (0.09)\n",
      "\n",
      "PCA (robust scaling)\n",
      "Average Accuracy: 0.89 (0.04)\n",
      "Average Precision: 0.76 (0.11)\n",
      "Average Recall: 0.77 (0.14)\n",
      "Average F1 Score: 0.76 (0.10)\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "rf_mdls, fts, *rf_metrics = LOSO_runner(data, RF, training_masks, validation_masks, testing_masks, test=False)\n",
    "print('\\nRobust Scaling')\n",
    "rf_rs_mdls, rs_fts, *rf_rs_metrics = LOSO_runner(rs_data, RF, *masks, test=False)\n",
    "print('\\nStandard Scaling')\n",
    "rf_ss_mdls, ss_fts, *rf_ss_metrics = LOSO_runner(ss_data, RF, *masks, test=False)\n",
    "print('\\nPCA (robust scaling)')\n",
    "rf_pca_mdls, pca_fts, *rf_pca_metrics = LOSO_runner(pca_data, RF, *masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a29155784f4c93ae0320bce94c61a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04da5ff435ce4cd7b745e9e5ba5cdc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31a5888bbc84e6eabb72ff9baf72a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_RF_feature_importances(rf_mdls, fts)\n",
    "plot_RF_feature_importances(rf_rs_mdls, fts)\n",
    "plot_RF_feature_importances(rf_ss_mdls, fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_subset = data.drop(['Skewness', 'Kurtosis', 'Autocorrelation', 'LinearSlope', 'SignalEntropy', \n",
    "#                          'ComplexityInvariantDistance', 'RangeCountPercentage', 'RatioBeyondRSigma',\n",
    "#                          'SpectralFlatness', 'Mean', 'MeanCrossRate', 'DominantFrequencyValue', 'RMS', 'DetailPowerRatio'], axis=1)\n",
    "data_subset = data.drop([\n",
    "    'LinearSlope',\n",
    "    'RatioBeyondRSigma',\n",
    "    'SpectralFlatness',\n",
    "    'ComplexityInvariantDistance',\n",
    "    'Kurtosis',\n",
    "    'Autocorrelation',\n",
    "    'DominantFrequencyValue',\n",
    "    'SignalEntropy',\n",
    "    'RangeCountPercentage'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.84 (0.09)\n",
      "Average Recall: 0.81 (0.14)\n",
      "Average F1 Score: 0.81 (0.09)\n"
     ]
    }
   ],
   "source": [
    "# check performance after dropping some of the less important features\n",
    "rfsub_mdls, sub_fts, *rfsub_metrics = LOSO_runner(data_subset, RF, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd751bd910f741f29ff7ae82faf66bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_RF_feature_importances(rfsub_mdls, sub_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.80 (0.10)\n",
      "Average Recall: 0.80 (0.14)\n",
      "Average F1 Score: 0.79 (0.09)\n"
     ]
    }
   ],
   "source": [
    "# check performance using DE features\n",
    "rfde_mdls, de_fts, *rfde_metrics = LOSO_runner(de_data, RF, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.87 (0.05)\n",
      "Average Precision: 0.82 (0.05)\n",
      "Average Recall: 0.88 (0.15)\n",
      "Average F1 Score: 0.84 (0.09)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1.0, kernel='rbf')\n",
    "\n",
    "svc_mdls, fts, *svc_metrics = LOSO_runner(data_subset, svc, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Scaling\n",
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.81 (0.10)\n",
      "Average Recall: 0.82 (0.15)\n",
      "Average F1 Score: 0.80 (0.09)\n",
      "\n",
      "Robust Scaling\n",
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.81 (0.10)\n",
      "Average Recall: 0.82 (0.15)\n",
      "Average F1 Score: 0.80 (0.09)\n",
      "\n",
      "Standard Scaling\n",
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.81 (0.10)\n",
      "Average Recall: 0.82 (0.15)\n",
      "Average F1 Score: 0.80 (0.09)\n",
      "\n",
      "PCA (robust scaling)\n",
      "Average Accuracy: 0.88 (0.04)\n",
      "Average Precision: 0.71 (0.13)\n",
      "Average Recall: 0.81 (0.14)\n",
      "Average F1 Score: 0.75 (0.10)\n"
     ]
    }
   ],
   "source": [
    "print('No Scaling')\n",
    "xgb_mdls, xgb_fts, xgb_accu, xgb_prec, xgb_rec, xgb_f1 = xgb_LOSO_runner(data, training_masks, validation_masks, testing_masks, test=False)\n",
    "print('\\nRobust Scaling')\n",
    "xgb_rs_mdls, xgb_rs_fts, *xgb_rs_metr = xgb_LOSO_runner(rs_data, *masks, test=False)\n",
    "print('\\nStandard Scaling')\n",
    "xgb_ss_mdls, xgb_ss_fts, *xgb_ss_metr = xgb_LOSO_runner(ss_data, *masks, test=False)\n",
    "print('\\nPCA (robust scaling)')\n",
    "xgb_pca_mdls, xgb_pca_fts, *xgb_pca_metr = xgb_LOSO_runner(pca_data, *masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_subset_2 = data.drop(['Mean', 'RatioBeyondRSigma', 'SpectralEntropy', 'SpectralFlatness', 'LinearSlope', 'RMS', 'Skewness', \n",
    "#                            'Kurtosis', 'Autocorrelation', 'DominantFrequencyValue', 'IQR', \n",
    "#                            'MeanCrossRate', 'ComplexityInvariantDistance', 'RangeCountPercentage', 'SignalEntropy', \n",
    "#                            'DimensionlessJerk', 'DetailPowerRatio', 'JerkMetric', 'SampleEntropy'], axis=1)\n",
    "data_subset_2 = data.drop([\n",
    "    'LinearSlope',\n",
    "    'SPARC',\n",
    "    'RatioBeyondRSigma',\n",
    "    'Mean',\n",
    "    'Kurtosis', \n",
    "    'PowerSpectralSum',\n",
    "    'IQR',\n",
    "    'RangeCountPercentage',\n",
    "    'DominantFrequencyValue',\n",
    "    'ComplexityInvariantDistance'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.79 (0.11)\n",
      "Average Recall: 0.84 (0.14)\n",
      "Average F1 Score: 0.80 (0.09)\n"
     ]
    }
   ],
   "source": [
    "xgb_s_mdls, xgb_s_fts, xgb_s_accu, xgb_s_prec, xgb_s_rec, xgb_s_f1 = xgb_LOSO_runner(data_subset_2, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfe1500b00e4a289d5a3999f55bd1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_xgb_feature_gains(xgb_s_mdls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.90 (0.04)\n",
      "Average Precision: 0.76 (0.12)\n",
      "Average Recall: 0.83 (0.15)\n",
      "Average F1 Score: 0.78 (0.10)\n"
     ]
    }
   ],
   "source": [
    "xgb_de_mdls, xgb_de_fts, xgb_de_accu, xgb_de_prec, xgb_de_rec, xgb_de_f1 = xgb_LOSO_runner(de_data, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-class Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.71 (0.11)\n",
      "Average Precision: 0.44 (0.20)\n",
      "Average Recall: 0.84 (0.12)\n",
      "Average F1 Score: 0.56 (0.18)\n"
     ]
    }
   ],
   "source": [
    "IF = IsolationForest(n_estimators=20)\n",
    "\n",
    "if_mdls, if_fts, *if_metr = unary_LOSO_runner(data, IF, *masks, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.80 (0.05)\n",
      "Average Precision: 0.54 (0.16)\n",
      "Average Recall: 0.44 (0.19)\n",
      "Average F1 Score: 0.46 (0.16)\n"
     ]
    }
   ],
   "source": [
    "usvc = OneClassSVM(kernel='rbf')\n",
    "\n",
    "usvc_mdls, _, *usvc_metr = unary_LOSO_runner(data, usvc, *masks, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Random Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take top half of features based on PP score\n",
    "dtophalf = data.drop([\n",
    "    'Skewness',\n",
    "    'Kurtosis',\n",
    "    'LinearSlope',\n",
    "    'SpectralFlatness',\n",
    "    'Autocorrelation',\n",
    "    'RangeCountPercentage',\n",
    "    'ComplexityInvariantDistance',\n",
    "    'PowerSpectralSum',\n",
    "    'RatioBeyondRSigma',\n",
    "    'SignalEntropy',\n",
    "    'DominantFrequencyValue',\n",
    "    'JerkMetric',  # add mean cross rate, remove Jerkmetric (correlation with DimensionlessJerk)\n",
    "    'StdDev'  # add mean, remove StdDev (high correlation with RMS)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, loguniform, randint\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = xgb.XGBClassifier()\n",
    "param_distributions = {\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'learning_rate': loguniform(1e-6, 1e-1),\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "}\n",
    "n_iter = 15 \n",
    "scoring = make_scorer(f1_score)\n",
    "n_jobs = -1  # use all possible cores\n",
    "refit = False  # don't want to refit on the whole dataset afterwards\n",
    "verbose = 2\n",
    "cv = ((training_masks[i], validation_masks[i]) for i in range(len(training_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(\n",
    "    estimator,\n",
    "    param_distributions,\n",
    "    cv=cv,\n",
    "    n_iter=n_iter,\n",
    "    scoring=scoring,\n",
    "    n_jobs=n_jobs,\n",
    "    refit=refit,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 15 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 12.3min finished\n"
     ]
    }
   ],
   "source": [
    "search = clf.fit(dtophalf.iloc[:, 3:], dtophalf.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_booster</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.989912</td>\n",
       "      <td>0.777379</td>\n",
       "      <td>0.027051</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.0951225</td>\n",
       "      <td>5</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.09512...</td>\n",
       "      <td>0.901780</td>\n",
       "      <td>0.894281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913772</td>\n",
       "      <td>0.906854</td>\n",
       "      <td>0.758340</td>\n",
       "      <td>0.601783</td>\n",
       "      <td>0.797901</td>\n",
       "      <td>0.675041</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.785832</td>\n",
       "      <td>0.113698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.253169</td>\n",
       "      <td>1.908233</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>0.011232</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.0114093</td>\n",
       "      <td>9</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.01140...</td>\n",
       "      <td>0.886945</td>\n",
       "      <td>0.850673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.732016</td>\n",
       "      <td>0.592488</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.633138</td>\n",
       "      <td>0.545301</td>\n",
       "      <td>0.763940</td>\n",
       "      <td>0.113126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.492019</td>\n",
       "      <td>1.127223</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.02291</td>\n",
       "      <td>7</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.02290...</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893706</td>\n",
       "      <td>0.894093</td>\n",
       "      <td>0.735791</td>\n",
       "      <td>0.581550</td>\n",
       "      <td>0.806743</td>\n",
       "      <td>0.627031</td>\n",
       "      <td>0.520868</td>\n",
       "      <td>0.760269</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.864725</td>\n",
       "      <td>1.623649</td>\n",
       "      <td>0.037767</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.00479575</td>\n",
       "      <td>9</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.00479...</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.822805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899340</td>\n",
       "      <td>0.880279</td>\n",
       "      <td>0.706331</td>\n",
       "      <td>0.577191</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.616095</td>\n",
       "      <td>0.565008</td>\n",
       "      <td>0.751631</td>\n",
       "      <td>0.114009</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64.079662</td>\n",
       "      <td>1.572281</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000165727</td>\n",
       "      <td>11</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.00016...</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>0.817381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892679</td>\n",
       "      <td>0.875130</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.805259</td>\n",
       "      <td>0.619860</td>\n",
       "      <td>0.519722</td>\n",
       "      <td>0.745520</td>\n",
       "      <td>0.115467</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>103.609675</td>\n",
       "      <td>5.342022</td>\n",
       "      <td>0.041676</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>dart</td>\n",
       "      <td>3.54542e-05</td>\n",
       "      <td>11</td>\n",
       "      <td>{'booster': 'dart', 'learning_rate': 3.5454233...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.814044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887124</td>\n",
       "      <td>0.879083</td>\n",
       "      <td>0.693055</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.808938</td>\n",
       "      <td>0.621359</td>\n",
       "      <td>0.507020</td>\n",
       "      <td>0.744235</td>\n",
       "      <td>0.116291</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48.361844</td>\n",
       "      <td>7.312645</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.014846</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>4.33497e-05</td>\n",
       "      <td>9</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 4.33496...</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.830620</td>\n",
       "      <td>0.853306</td>\n",
       "      <td>0.702784</td>\n",
       "      <td>0.544386</td>\n",
       "      <td>0.811051</td>\n",
       "      <td>0.602919</td>\n",
       "      <td>0.723377</td>\n",
       "      <td>0.739806</td>\n",
       "      <td>0.103375</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53.161303</td>\n",
       "      <td>1.660655</td>\n",
       "      <td>0.034522</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000700963</td>\n",
       "      <td>9</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.00070...</td>\n",
       "      <td>0.870634</td>\n",
       "      <td>0.799541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873622</td>\n",
       "      <td>0.859269</td>\n",
       "      <td>0.707085</td>\n",
       "      <td>0.532086</td>\n",
       "      <td>0.776045</td>\n",
       "      <td>0.606785</td>\n",
       "      <td>0.533858</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>0.119292</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.602757</td>\n",
       "      <td>1.246270</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.00647376</td>\n",
       "      <td>5</td>\n",
       "      <td>{'booster': 'dart', 'learning_rate': 0.0064737...</td>\n",
       "      <td>0.835346</td>\n",
       "      <td>0.714045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814026</td>\n",
       "      <td>0.887440</td>\n",
       "      <td>0.685131</td>\n",
       "      <td>0.498634</td>\n",
       "      <td>0.820829</td>\n",
       "      <td>0.434634</td>\n",
       "      <td>0.557089</td>\n",
       "      <td>0.704958</td>\n",
       "      <td>0.147764</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.874733</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.017218</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.0168764</td>\n",
       "      <td>3</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.01687...</td>\n",
       "      <td>0.832827</td>\n",
       "      <td>0.672439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763048</td>\n",
       "      <td>0.867777</td>\n",
       "      <td>0.645820</td>\n",
       "      <td>0.531959</td>\n",
       "      <td>0.798623</td>\n",
       "      <td>0.491004</td>\n",
       "      <td>0.691014</td>\n",
       "      <td>0.689647</td>\n",
       "      <td>0.122094</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27.455645</td>\n",
       "      <td>0.933715</td>\n",
       "      <td>0.014997</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>dart</td>\n",
       "      <td>1.00181e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>{'booster': 'dart', 'learning_rate': 1.0018133...</td>\n",
       "      <td>0.619696</td>\n",
       "      <td>0.686271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653712</td>\n",
       "      <td>0.782249</td>\n",
       "      <td>0.521842</td>\n",
       "      <td>0.575663</td>\n",
       "      <td>0.821442</td>\n",
       "      <td>0.352083</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>0.633261</td>\n",
       "      <td>0.147815</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27.521454</td>\n",
       "      <td>0.635164</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>dart</td>\n",
       "      <td>1.06095e-05</td>\n",
       "      <td>3</td>\n",
       "      <td>{'booster': 'dart', 'learning_rate': 1.0609513...</td>\n",
       "      <td>0.619696</td>\n",
       "      <td>0.686271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653712</td>\n",
       "      <td>0.782249</td>\n",
       "      <td>0.521842</td>\n",
       "      <td>0.575663</td>\n",
       "      <td>0.821442</td>\n",
       "      <td>0.352083</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>0.633261</td>\n",
       "      <td>0.147815</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.170911</td>\n",
       "      <td>0.074674</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>0.037979</td>\n",
       "      <td>11</td>\n",
       "      <td>{'booster': 'gblinear', 'learning_rate': 0.037...</td>\n",
       "      <td>0.564924</td>\n",
       "      <td>0.495557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444306</td>\n",
       "      <td>0.895264</td>\n",
       "      <td>0.753974</td>\n",
       "      <td>0.568776</td>\n",
       "      <td>0.409296</td>\n",
       "      <td>0.478203</td>\n",
       "      <td>0.793761</td>\n",
       "      <td>0.597791</td>\n",
       "      <td>0.136761</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.218287</td>\n",
       "      <td>0.081812</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>0.000787361</td>\n",
       "      <td>11</td>\n",
       "      <td>{'booster': 'gblinear', 'learning_rate': 0.000...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.162519</td>\n",
       "      <td>0.073545</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>0.000796279</td>\n",
       "      <td>7</td>\n",
       "      <td>{'booster': 'gblinear', 'learning_rate': 0.000...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5       28.989912      0.777379         0.027051        0.007716   \n",
       "0       55.253169      1.908233         0.039049        0.011232   \n",
       "7       41.492019      1.127223         0.030755        0.009024   \n",
       "1       53.864725      1.623649         0.037767        0.011843   \n",
       "10      64.079662      1.572281         0.042683        0.012507   \n",
       "13     103.609675      5.342022         0.041676        0.015322   \n",
       "14      48.361844      7.312645         0.029272        0.014846   \n",
       "11      53.161303      1.660655         0.034522        0.010910   \n",
       "2       46.602757      1.246270         0.021330        0.006126   \n",
       "4       17.874733      0.588752         0.017218        0.004612   \n",
       "9       27.455645      0.933715         0.014997        0.004010   \n",
       "12      27.521454      0.635164         0.014837        0.003722   \n",
       "8        3.170911      0.074674         0.006194        0.001160   \n",
       "3        3.218287      0.081812         0.005987        0.001043   \n",
       "6        3.162519      0.073545         0.006079        0.001071   \n",
       "\n",
       "   param_booster param_learning_rate param_max_depth  \\\n",
       "5         gbtree           0.0951225               5   \n",
       "0         gbtree           0.0114093               9   \n",
       "7         gbtree             0.02291               7   \n",
       "1         gbtree          0.00479575               9   \n",
       "10        gbtree         0.000165727              11   \n",
       "13          dart         3.54542e-05              11   \n",
       "14        gbtree         4.33497e-05               9   \n",
       "11        gbtree         0.000700963               9   \n",
       "2           dart          0.00647376               5   \n",
       "4         gbtree           0.0168764               3   \n",
       "9           dart         1.00181e-05               3   \n",
       "12          dart         1.06095e-05               3   \n",
       "8       gblinear            0.037979              11   \n",
       "3       gblinear         0.000787361              11   \n",
       "6       gblinear         0.000796279               7   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "5   {'booster': 'gbtree', 'learning_rate': 0.09512...           0.901780   \n",
       "0   {'booster': 'gbtree', 'learning_rate': 0.01140...           0.886945   \n",
       "7   {'booster': 'gbtree', 'learning_rate': 0.02290...           0.882979   \n",
       "1   {'booster': 'gbtree', 'learning_rate': 0.00479...           0.875912   \n",
       "10  {'booster': 'gbtree', 'learning_rate': 0.00016...           0.860172   \n",
       "13  {'booster': 'dart', 'learning_rate': 3.5454233...           0.857143   \n",
       "14  {'booster': 'gbtree', 'learning_rate': 4.33496...           0.864865   \n",
       "11  {'booster': 'gbtree', 'learning_rate': 0.00070...           0.870634   \n",
       "2   {'booster': 'dart', 'learning_rate': 0.0064737...           0.835346   \n",
       "4   {'booster': 'gbtree', 'learning_rate': 0.01687...           0.832827   \n",
       "9   {'booster': 'dart', 'learning_rate': 1.0018133...           0.619696   \n",
       "12  {'booster': 'dart', 'learning_rate': 1.0609513...           0.619696   \n",
       "8   {'booster': 'gblinear', 'learning_rate': 0.037...           0.564924   \n",
       "3   {'booster': 'gblinear', 'learning_rate': 0.000...           0.000000   \n",
       "6   {'booster': 'gblinear', 'learning_rate': 0.000...           0.000000   \n",
       "\n",
       "    split1_test_score  ...  split8_test_score  split9_test_score  \\\n",
       "5            0.894281  ...           0.913772           0.906854   \n",
       "0            0.850673  ...           0.902429           0.883607   \n",
       "7            0.810675  ...           0.893706           0.894093   \n",
       "1            0.822805  ...           0.899340           0.880279   \n",
       "10           0.817381  ...           0.892679           0.875130   \n",
       "13           0.814044  ...           0.887124           0.879083   \n",
       "14           0.789474  ...           0.830620           0.853306   \n",
       "11           0.799541  ...           0.873622           0.859269   \n",
       "2            0.714045  ...           0.814026           0.887440   \n",
       "4            0.672439  ...           0.763048           0.867777   \n",
       "9            0.686271  ...           0.653712           0.782249   \n",
       "12           0.686271  ...           0.653712           0.782249   \n",
       "8            0.495557  ...           0.444306           0.895264   \n",
       "3            0.000000  ...           0.000000           0.000000   \n",
       "6            0.000000  ...           0.000000           0.000000   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "5             0.758340            0.601783            0.797901   \n",
       "0             0.732016            0.592488            0.816368   \n",
       "7             0.735791            0.581550            0.806743   \n",
       "1             0.706331            0.577191            0.813242   \n",
       "10            0.697885            0.542614            0.805259   \n",
       "13            0.693055            0.542614            0.808938   \n",
       "14            0.702784            0.544386            0.811051   \n",
       "11            0.707085            0.532086            0.776045   \n",
       "2             0.685131            0.498634            0.820829   \n",
       "4             0.645820            0.531959            0.798623   \n",
       "9             0.521842            0.575663            0.821442   \n",
       "12            0.521842            0.575663            0.821442   \n",
       "8             0.753974            0.568776            0.409296   \n",
       "3             0.000000            0.000000            0.000000   \n",
       "6             0.000000            0.000000            0.000000   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "5             0.675041            0.549296         0.785832        0.113698   \n",
       "0             0.633138            0.545301         0.763940        0.113126   \n",
       "7             0.627031            0.520868         0.760269        0.119998   \n",
       "1             0.616095            0.565008         0.751631        0.114009   \n",
       "10            0.619860            0.519722         0.745520        0.115467   \n",
       "13            0.621359            0.507020         0.744235        0.116291   \n",
       "14            0.602919            0.723377         0.739806        0.103375   \n",
       "11            0.606785            0.533858         0.729246        0.119292   \n",
       "2             0.434634            0.557089         0.704958        0.147764   \n",
       "4             0.491004            0.691014         0.689647        0.122094   \n",
       "9             0.352083            0.414035         0.633261        0.147815   \n",
       "12            0.352083            0.414035         0.633261        0.147815   \n",
       "8             0.478203            0.793761         0.597791        0.136761   \n",
       "3             0.000000            0.000000         0.000000        0.000000   \n",
       "6             0.000000            0.000000         0.000000        0.000000   \n",
       "\n",
       "    rank_test_score  \n",
       "5                 1  \n",
       "0                 2  \n",
       "7                 3  \n",
       "1                 4  \n",
       "10                5  \n",
       "13                6  \n",
       "14                7  \n",
       "11                8  \n",
       "2                 9  \n",
       "4                10  \n",
       "9                11  \n",
       "12               11  \n",
       "8                13  \n",
       "3                14  \n",
       "6                14  \n",
       "\n",
       "[15 rows x 26 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(data=search.cv_results_)\n",
    "cv_results.to_csv('xgboost_cv_results_topfeats.csv')\n",
    "cv_results.sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier Random CV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier()\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(5, 100),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 7, 10, 13, 16, None],\n",
    "    'min_samples_split': [2, 10, 20, 50, 100, 500, 1000],\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16, 32]\n",
    "}\n",
    "n_iter = 25\n",
    "scoring = make_scorer(f1_score)\n",
    "n_jobs = -1  # use all possible cores\n",
    "refit = False  # don't want to refit on the whole dataset afterwards\n",
    "verbose = 2\n",
    "cv = ((training_masks[i], validation_masks[i]) for i in range(len(training_masks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomizedSearchCV(\n",
    "    estimator,\n",
    "    param_distributions,\n",
    "    cv=cv,\n",
    "    n_iter=n_iter,\n",
    "    scoring=scoring,\n",
    "    n_jobs=n_jobs,\n",
    "    refit=refit,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 25 candidates, totalling 375 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   30.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-51041d89e2f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[1;32m   1530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             random_state=self.random_state))\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pfymu/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "search = clf.fit(data.iloc[:, 3:], data.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost cutoff analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_booster</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>130.157791</td>\n",
       "      <td>4.596821</td>\n",
       "      <td>0.046471</td>\n",
       "      <td>0.012082</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>11</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 5.45993...</td>\n",
       "      <td>0.873916</td>\n",
       "      <td>0.847865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906433</td>\n",
       "      <td>0.908223</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.625861</td>\n",
       "      <td>0.774995</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.568938</td>\n",
       "      <td>0.773441</td>\n",
       "      <td>0.089838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>106.544220</td>\n",
       "      <td>3.497599</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>9</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.00010...</td>\n",
       "      <td>0.877099</td>\n",
       "      <td>0.828001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.900111</td>\n",
       "      <td>0.782918</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.815859</td>\n",
       "      <td>0.649054</td>\n",
       "      <td>0.609105</td>\n",
       "      <td>0.759521</td>\n",
       "      <td>0.091498</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.827195</td>\n",
       "      <td>1.315661</td>\n",
       "      <td>0.023987</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>5</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.01000...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.708221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862694</td>\n",
       "      <td>0.893108</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.608817</td>\n",
       "      <td>0.815188</td>\n",
       "      <td>0.635332</td>\n",
       "      <td>0.568038</td>\n",
       "      <td>0.739639</td>\n",
       "      <td>0.105794</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>105.427766</td>\n",
       "      <td>2.409746</td>\n",
       "      <td>0.029812</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>7</td>\n",
       "      <td>{'booster': 'dart', 'learning_rate': 9.7752501...</td>\n",
       "      <td>0.896417</td>\n",
       "      <td>0.805088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869712</td>\n",
       "      <td>0.886669</td>\n",
       "      <td>0.773984</td>\n",
       "      <td>0.595556</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.644856</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.737760</td>\n",
       "      <td>0.106544</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.375426</td>\n",
       "      <td>2.800545</td>\n",
       "      <td>0.027003</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>7</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 9.33257...</td>\n",
       "      <td>0.892927</td>\n",
       "      <td>0.799109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869712</td>\n",
       "      <td>0.886241</td>\n",
       "      <td>0.773984</td>\n",
       "      <td>0.595556</td>\n",
       "      <td>0.774030</td>\n",
       "      <td>0.644856</td>\n",
       "      <td>0.548552</td>\n",
       "      <td>0.736368</td>\n",
       "      <td>0.105799</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "9      130.157791      4.596821         0.046471        0.012082   \n",
       "11     106.544220      3.497599         0.038598        0.011275   \n",
       "2       57.827195      1.315661         0.023987        0.006872   \n",
       "7      105.427766      2.409746         0.029812        0.009498   \n",
       "1       81.375426      2.800545         0.027003        0.007098   \n",
       "\n",
       "   param_booster  param_learning_rate  param_max_depth  \\\n",
       "9         gbtree             0.000055               11   \n",
       "11        gbtree             0.000103                9   \n",
       "2         gbtree             0.010004                5   \n",
       "7           dart             0.000098                7   \n",
       "1         gbtree             0.000009                7   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "9   {'booster': 'gbtree', 'learning_rate': 5.45993...           0.873916   \n",
       "11  {'booster': 'gbtree', 'learning_rate': 0.00010...           0.877099   \n",
       "2   {'booster': 'gbtree', 'learning_rate': 0.01000...           0.870968   \n",
       "7   {'booster': 'dart', 'learning_rate': 9.7752501...           0.896417   \n",
       "1   {'booster': 'gbtree', 'learning_rate': 9.33257...           0.892927   \n",
       "\n",
       "    split1_test_score  ...  split8_test_score  split9_test_score  \\\n",
       "9            0.847865  ...           0.906433           0.908223   \n",
       "11           0.828001  ...           0.887097           0.900111   \n",
       "2            0.708221  ...           0.862694           0.893108   \n",
       "7            0.805088  ...           0.869712           0.886669   \n",
       "1            0.799109  ...           0.869712           0.886241   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "9             0.798942            0.625861            0.774995   \n",
       "11            0.782918            0.615385            0.815859   \n",
       "2             0.781667            0.608817            0.815188   \n",
       "7             0.773984            0.595556            0.771429   \n",
       "1             0.773984            0.595556            0.774030   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "9             0.736842            0.568938         0.773441        0.089838   \n",
       "11            0.649054            0.609105         0.759521        0.091498   \n",
       "2             0.635332            0.568038         0.739639        0.105794   \n",
       "7             0.644856            0.549020         0.737760        0.106544   \n",
       "1             0.644856            0.548552         0.736368        0.105799   \n",
       "\n",
       "    rank_test_score  \n",
       "9                 1  \n",
       "11                2  \n",
       "2                 3  \n",
       "7                 4  \n",
       "1                 5  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvr = pd.read_csv('xgboost_cv_results.csv', index_col=0)\n",
    "cvr.sort_values('mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_booster</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.989912</td>\n",
       "      <td>0.777379</td>\n",
       "      <td>0.027051</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.095123</td>\n",
       "      <td>5</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.09512...</td>\n",
       "      <td>0.901780</td>\n",
       "      <td>0.894281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913772</td>\n",
       "      <td>0.906854</td>\n",
       "      <td>0.758340</td>\n",
       "      <td>0.601783</td>\n",
       "      <td>0.797901</td>\n",
       "      <td>0.675041</td>\n",
       "      <td>0.549296</td>\n",
       "      <td>0.785832</td>\n",
       "      <td>0.113698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55.253169</td>\n",
       "      <td>1.908233</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>0.011232</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>9</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.01140...</td>\n",
       "      <td>0.886945</td>\n",
       "      <td>0.850673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902429</td>\n",
       "      <td>0.883607</td>\n",
       "      <td>0.732016</td>\n",
       "      <td>0.592488</td>\n",
       "      <td>0.816368</td>\n",
       "      <td>0.633138</td>\n",
       "      <td>0.545301</td>\n",
       "      <td>0.763940</td>\n",
       "      <td>0.113126</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41.492019</td>\n",
       "      <td>1.127223</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.022910</td>\n",
       "      <td>7</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.02290...</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893706</td>\n",
       "      <td>0.894093</td>\n",
       "      <td>0.735791</td>\n",
       "      <td>0.581550</td>\n",
       "      <td>0.806743</td>\n",
       "      <td>0.627031</td>\n",
       "      <td>0.520868</td>\n",
       "      <td>0.760269</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53.864725</td>\n",
       "      <td>1.623649</td>\n",
       "      <td>0.037767</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>9</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.00479...</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.822805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899340</td>\n",
       "      <td>0.880279</td>\n",
       "      <td>0.706331</td>\n",
       "      <td>0.577191</td>\n",
       "      <td>0.813242</td>\n",
       "      <td>0.616095</td>\n",
       "      <td>0.565008</td>\n",
       "      <td>0.751631</td>\n",
       "      <td>0.114009</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64.079662</td>\n",
       "      <td>1.572281</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>11</td>\n",
       "      <td>{'booster': 'gbtree', 'learning_rate': 0.00016...</td>\n",
       "      <td>0.860172</td>\n",
       "      <td>0.817381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892679</td>\n",
       "      <td>0.875130</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.542614</td>\n",
       "      <td>0.805259</td>\n",
       "      <td>0.619860</td>\n",
       "      <td>0.519722</td>\n",
       "      <td>0.745520</td>\n",
       "      <td>0.115467</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "5       28.989912      0.777379         0.027051        0.007716   \n",
       "0       55.253169      1.908233         0.039049        0.011232   \n",
       "7       41.492019      1.127223         0.030755        0.009024   \n",
       "1       53.864725      1.623649         0.037767        0.011843   \n",
       "10      64.079662      1.572281         0.042683        0.012507   \n",
       "\n",
       "   param_booster  param_learning_rate  param_max_depth  \\\n",
       "5         gbtree             0.095123                5   \n",
       "0         gbtree             0.011409                9   \n",
       "7         gbtree             0.022910                7   \n",
       "1         gbtree             0.004796                9   \n",
       "10        gbtree             0.000166               11   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "5   {'booster': 'gbtree', 'learning_rate': 0.09512...           0.901780   \n",
       "0   {'booster': 'gbtree', 'learning_rate': 0.01140...           0.886945   \n",
       "7   {'booster': 'gbtree', 'learning_rate': 0.02290...           0.882979   \n",
       "1   {'booster': 'gbtree', 'learning_rate': 0.00479...           0.875912   \n",
       "10  {'booster': 'gbtree', 'learning_rate': 0.00016...           0.860172   \n",
       "\n",
       "    split1_test_score  ...  split8_test_score  split9_test_score  \\\n",
       "5            0.894281  ...           0.913772           0.906854   \n",
       "0            0.850673  ...           0.902429           0.883607   \n",
       "7            0.810675  ...           0.893706           0.894093   \n",
       "1            0.822805  ...           0.899340           0.880279   \n",
       "10           0.817381  ...           0.892679           0.875130   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "5             0.758340            0.601783            0.797901   \n",
       "0             0.732016            0.592488            0.816368   \n",
       "7             0.735791            0.581550            0.806743   \n",
       "1             0.706331            0.577191            0.813242   \n",
       "10            0.697885            0.542614            0.805259   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "5             0.675041            0.549296         0.785832        0.113698   \n",
       "0             0.633138            0.545301         0.763940        0.113126   \n",
       "7             0.627031            0.520868         0.760269        0.119998   \n",
       "1             0.616095            0.565008         0.751631        0.114009   \n",
       "10            0.619860            0.519722         0.745520        0.115467   \n",
       "\n",
       "    rank_test_score  \n",
       "5                 1  \n",
       "0                 2  \n",
       "7                 3  \n",
       "1                 4  \n",
       "10                5  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvr2 = pd.read_csv('xgboost_cv_results_topfeats.csv', index_col=0)\n",
    "cvr2.sort_values('mean_test_score', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
