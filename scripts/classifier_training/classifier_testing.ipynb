{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random # shuffle the subjects\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_curve, auc\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOSO_runner(data, model, train_masks, validate_masks, test_masks, test=False):    \n",
    "    # seperate the features out\n",
    "    feats = data.drop(['Subject', 'Activity', 'Label'], axis=1)\n",
    "    \n",
    "    # metrics\n",
    "    accu = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    \n",
    "    # return the models\n",
    "    mdls = []\n",
    "    \n",
    "    # iterate over groups of N_lo subjects to leave out\n",
    "    if test:\n",
    "        itr = zip(train_masks, test_masks)\n",
    "    else:\n",
    "        itr = zip(train_masks, validate_masks)\n",
    "    for train_mask, pred_mask in itr:\n",
    "        clm = clone(model)\n",
    "        clm.fit(feats.loc[train_mask], data.Label[train_mask])\n",
    "        \n",
    "        y_pred = clm.predict(feats.loc[pred_mask])\n",
    "        y_true = data.Label[pred_mask]\n",
    "        \n",
    "        accu.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "        prec.append(precision_score(y_true, y_pred))\n",
    "        rec.append(recall_score(y_true, y_pred))\n",
    "        f1.append(f1_score(y_true, y_pred))\n",
    "        \n",
    "        mdls.append(clm)\n",
    "    \n",
    "    print(f'Average Accuracy: {np.mean(accu):.2f} ({np.std(accu):.2f})')\n",
    "    print(f'Average Precision: {np.mean(prec):.2f} ({np.std(prec):.2f})')\n",
    "    print(f'Average Recall: {np.mean(rec):.2f} ({np.std(rec):.2f})')\n",
    "    print(f'Average F1 Score: {np.mean(f1):.2f} ({np.std(f1):.2f})')\n",
    "        \n",
    "    return mdls, feats.columns, accu, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_LOSO_runner(data, train_masks, validate_masks, test_masks, test=False):\n",
    "    feats = data.drop(['Subject', 'Activity', 'Label'], axis=1)\n",
    "    labels = data.Label\n",
    "    \n",
    "    # metrics\n",
    "    accu = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    \n",
    "    # return the models\n",
    "    mdls = []\n",
    "    \n",
    "    # iterate over groups of N_lo subjects to leave out    \n",
    "    for train_mask, val_mask, test_mask in zip(train_masks, validate_masks, test_masks):\n",
    "        dtrain = xgb.DMatrix(feats.loc[train_mask], label=labels.loc[train_mask])\n",
    "        dval = xgb.DMatrix(feats.loc[val_mask], label=labels.loc[val_mask])\n",
    "        if test:\n",
    "            dtest = xgb.DMatrix(feats.loc[test_mask], label=labels.loc[test_mask])\n",
    "\n",
    "        params = {\n",
    "            'max_depth': 8,  # default\n",
    "            'eval_metric': ['rmse', 'auc']\n",
    "        }\n",
    "        eval_list = [(dval, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "        bst = xgb.train(params, dtrain, 10, eval_list, verbose_eval=False)\n",
    "        \n",
    "        if test:\n",
    "            y_pred = bst.predict(dtest) > 0.5\n",
    "            y_true = labels.loc[test_mask]\n",
    "        else:\n",
    "            y_pred = bst.predict(dval) > 0.5\n",
    "            y_true = labels.loc[val_mask]\n",
    "        \n",
    "        accu.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "        prec.append(precision_score(y_true, y_pred))\n",
    "        rec.append(recall_score(y_true, y_pred))\n",
    "        f1.append(f1_score(y_true, y_pred))\n",
    "        \n",
    "        mdls.append(bst)\n",
    "        \n",
    "    print(f'Average Accuracy: {np.mean(accu):.2f} ({np.std(accu):.2f})')\n",
    "    print(f'Average Precision: {np.mean(prec):.2f} ({np.std(prec):.2f})')\n",
    "    print(f'Average Recall: {np.mean(rec):.2f} ({np.std(rec):.2f})')\n",
    "    print(f'Average F1 Score: {np.mean(f1):.2f} ({np.std(f1):.2f})')\n",
    "        \n",
    "    return mdls, feats.columns, accu, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unary_LOSO_runner(data, model, train_masks, validate_masks, test_masks, test=False):\n",
    "    feats = data.drop(['Subject', 'Activity', 'Label'], axis=1)\n",
    "    labels = data.Label\n",
    "    \n",
    "    # metrics\n",
    "    accu = []\n",
    "    prec = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "    \n",
    "    # return the models\n",
    "    mdls = []\n",
    "    \n",
    "    # iterate over groups of N_lo subjects to leave out    \n",
    "    if test:\n",
    "        itr = zip(train_masks, test_masks)\n",
    "    else:\n",
    "        itr = zip(train_masks, validate_masks)\n",
    "    for train_mask, pred_mask in itr:\n",
    "        clm = clone(model)\n",
    "        clm.fit(feats.loc[train_mask & (labels == 1)])\n",
    "        \n",
    "        y_pred = clm.predict(feats.loc[pred_mask])\n",
    "        y_pred[y_pred == -1] = 0\n",
    "        y_true = data.Label[pred_mask]\n",
    "        \n",
    "        accu.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "        prec.append(precision_score(y_true, y_pred))\n",
    "        rec.append(recall_score(y_true, y_pred))\n",
    "        f1.append(f1_score(y_true, y_pred))\n",
    "        \n",
    "        mdls.append(clm)\n",
    "        \n",
    "    print(f'Average Accuracy: {np.mean(accu):.2f} ({np.std(accu):.2f})')\n",
    "    print(f'Average Precision: {np.mean(prec):.2f} ({np.std(prec):.2f})')\n",
    "    print(f'Average Recall: {np.mean(rec):.2f} ({np.std(rec):.2f})')\n",
    "    print(f'Average F1 Score: {np.mean(f1):.2f} ({np.std(f1):.2f})')\n",
    "        \n",
    "    return mdls, feats.columns, accu, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_RF_feature_importances(models, features):\n",
    "    ft_impt = pd.DataFrame(columns=['Feature', 'Importance'])\n",
    "    ft_impt['Importance'] = [i for L in models for i in L.feature_importances_]\n",
    "    ft_impt['Feature'] = np.tile(features, len(models))\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.violinplot(x='Feature', y='Importance', data=ft_impt, ax=ax, width=1, scale='width', bw=0.25)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xgb_feature_gains(models):\n",
    "    df = pd.DataFrame(columns=['Feature', 'Split', 'Gain'])\n",
    "    \n",
    "    df['Feature'] = [i for d in models for i in d.get_score(importance_type='gain')]\n",
    "    df['Split'] = np.repeat(np.arange(len(models)), len(models[0].get_score()))\n",
    "    df['Gain'] = [i for d in models for i in d.get_score(importance_type='gain').values()]\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.boxplot(x='Feature', y='Gain', data=df)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf('../feature_exploration/features.h5', key='no_preprocessing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the subjects for which LOSO actually makes sense: those with multiple activities (ie more than just walking)\n",
    "gbc = data.groupby(['Subject', 'Activity'], as_index=False).count()\n",
    "loso_subjects = [i for i in gbc.Subject.unique() if gbc.loc[gbc.Subject == i].shape[0] > 3]\n",
    "\n",
    "random.seed(5)  # fix the generation so that its the same every time\n",
    "random.shuffle(loso_subjects)\n",
    "\n",
    "training_masks = []\n",
    "validation_masks = []\n",
    "testing_masks = []\n",
    "\n",
    "for i in range(0, len(loso_subjects), 3):\n",
    "    tr_m = np.ones(data.shape[0], dtype='bool')\n",
    "    v_m = np.zeros(data.shape[0], dtype='bool')\n",
    "    \n",
    "    for j in range(3):\n",
    "        tr_m &= data.Subject != loso_subjects[i+j]\n",
    "    for j in range(2):\n",
    "        v_m |= data.Subject == loso_subjects[i+j]\n",
    "    te_m = data.Subject == loso_subjects[i+2]\n",
    "    \n",
    "    training_masks.append(tr_m)\n",
    "    validation_masks.append(v_m)\n",
    "    testing_masks.append(te_m)\n",
    "\n",
    "masks = (training_masks, validation_masks, testing_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain expert feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_data = data.drop([\n",
    "    'Mean',\n",
    "    'Skewness',\n",
    "    'Kurtosis',\n",
    "    'RMS',\n",
    "    'LinearSlope',\n",
    "    'ComplexityInvariantDistance',\n",
    "    'RangeCountPercentage',\n",
    "    'RatioBeyondRSigma',\n",
    "    'JerkMetric',\n",
    "    'DominantFrequencyValue',\n",
    "    'DetailPower',\n",
    "    'SignalEntropy',\n",
    "    'SpectralFlatness'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_data = data.copy()\n",
    "rs_data.iloc[:, 3:] = RobustScaler().fit_transform(data.iloc[:, 3:])\n",
    "ss_data = data.copy()\n",
    "ss_data.iloc[:, 3:] = StandardScaler().fit_transform(data.iloc[:, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca_data = data.iloc[:, :3].copy()\n",
    "pca_data = pca_data.merge(pd.DataFrame(pca.fit_transform(rs_data.iloc[:, 3:])), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.84 (0.09)\n",
      "Average Recall: 0.81 (0.15)\n",
      "Average F1 Score: 0.81 (0.10)\n",
      "\n",
      "Robust Scaling\n",
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.85 (0.09)\n",
      "Average Recall: 0.81 (0.14)\n",
      "Average F1 Score: 0.82 (0.09)\n",
      "\n",
      "Standard Scaling\n",
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.85 (0.09)\n",
      "Average Recall: 0.81 (0.15)\n",
      "Average F1 Score: 0.82 (0.09)\n",
      "\n",
      "PCA (robust scaling)\n",
      "Average Accuracy: 0.89 (0.04)\n",
      "Average Precision: 0.76 (0.11)\n",
      "Average Recall: 0.77 (0.14)\n",
      "Average F1 Score: 0.76 (0.10)\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "rf_mdls, fts, *rf_metrics = LOSO_runner(data, RF, training_masks, validation_masks, testing_masks, test=False)\n",
    "print('\\nRobust Scaling')\n",
    "rf_rs_mdls, rs_fts, *rf_rs_metrics = LOSO_runner(rs_data, RF, *masks, test=False)\n",
    "print('\\nStandard Scaling')\n",
    "rf_ss_mdls, ss_fts, *rf_ss_metrics = LOSO_runner(ss_data, RF, *masks, test=False)\n",
    "print('\\nPCA (robust scaling)')\n",
    "rf_pca_mdls, pca_fts, *rf_pca_metrics = LOSO_runner(pca_data, RF, *masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a29155784f4c93ae0320bce94c61a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04da5ff435ce4cd7b745e9e5ba5cdc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31a5888bbc84e6eabb72ff9baf72a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_RF_feature_importances(rf_mdls, fts)\n",
    "plot_RF_feature_importances(rf_rs_mdls, fts)\n",
    "plot_RF_feature_importances(rf_ss_mdls, fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_subset = data.drop(['Skewness', 'Kurtosis', 'Autocorrelation', 'LinearSlope', 'SignalEntropy', \n",
    "#                          'ComplexityInvariantDistance', 'RangeCountPercentage', 'RatioBeyondRSigma',\n",
    "#                          'SpectralFlatness', 'Mean', 'MeanCrossRate', 'DominantFrequencyValue', 'RMS', 'DetailPowerRatio'], axis=1)\n",
    "data_subset = data.drop([\n",
    "    'LinearSlope',\n",
    "    'RatioBeyondRSigma',\n",
    "    'SpectralFlatness',\n",
    "    'ComplexityInvariantDistance',\n",
    "    'Kurtosis',\n",
    "    'Autocorrelation',\n",
    "    'DominantFrequencyValue',\n",
    "    'SignalEntropy',\n",
    "    'RangeCountPercentage'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.92 (0.03)\n",
      "Average Precision: 0.84 (0.09)\n",
      "Average Recall: 0.81 (0.14)\n",
      "Average F1 Score: 0.81 (0.09)\n"
     ]
    }
   ],
   "source": [
    "# check performance after dropping some of the less important features\n",
    "rfsub_mdls, sub_fts, *rfsub_metrics = LOSO_runner(data_subset, RF, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd751bd910f741f29ff7ae82faf66bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_RF_feature_importances(rfsub_mdls, sub_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.80 (0.10)\n",
      "Average Recall: 0.80 (0.14)\n",
      "Average F1 Score: 0.79 (0.09)\n"
     ]
    }
   ],
   "source": [
    "# check performance using DE features\n",
    "rfde_mdls, de_fts, *rfde_metrics = LOSO_runner(de_data, RF, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.87 (0.05)\n",
      "Average Precision: 0.82 (0.05)\n",
      "Average Recall: 0.88 (0.15)\n",
      "Average F1 Score: 0.84 (0.09)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1.0, kernel='rbf')\n",
    "\n",
    "svc_mdls, fts, *svc_metrics = LOSO_runner(data_subset, svc, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Scaling\n",
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.81 (0.10)\n",
      "Average Recall: 0.82 (0.15)\n",
      "Average F1 Score: 0.80 (0.09)\n",
      "\n",
      "Robust Scaling\n",
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.81 (0.10)\n",
      "Average Recall: 0.82 (0.15)\n",
      "Average F1 Score: 0.80 (0.09)\n",
      "\n",
      "Standard Scaling\n",
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.81 (0.10)\n",
      "Average Recall: 0.82 (0.15)\n",
      "Average F1 Score: 0.80 (0.09)\n",
      "\n",
      "PCA (robust scaling)\n",
      "Average Accuracy: 0.88 (0.04)\n",
      "Average Precision: 0.71 (0.13)\n",
      "Average Recall: 0.81 (0.14)\n",
      "Average F1 Score: 0.75 (0.10)\n"
     ]
    }
   ],
   "source": [
    "print('No Scaling')\n",
    "xgb_mdls, xgb_fts, xgb_accu, xgb_prec, xgb_rec, xgb_f1 = xgb_LOSO_runner(data, training_masks, validation_masks, testing_masks, test=False)\n",
    "print('\\nRobust Scaling')\n",
    "xgb_rs_mdls, xgb_rs_fts, *xgb_rs_metr = xgb_LOSO_runner(rs_data, *masks, test=False)\n",
    "print('\\nStandard Scaling')\n",
    "xgb_ss_mdls, xgb_ss_fts, *xgb_ss_metr = xgb_LOSO_runner(ss_data, *masks, test=False)\n",
    "print('\\nPCA (robust scaling)')\n",
    "xgb_pca_mdls, xgb_pca_fts, *xgb_pca_metr = xgb_LOSO_runner(pca_data, *masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_subset_2 = data.drop(['Mean', 'RatioBeyondRSigma', 'SpectralEntropy', 'SpectralFlatness', 'LinearSlope', 'RMS', 'Skewness', \n",
    "#                            'Kurtosis', 'Autocorrelation', 'DominantFrequencyValue', 'IQR', \n",
    "#                            'MeanCrossRate', 'ComplexityInvariantDistance', 'RangeCountPercentage', 'SignalEntropy', \n",
    "#                            'DimensionlessJerk', 'DetailPowerRatio', 'JerkMetric', 'SampleEntropy'], axis=1)\n",
    "data_subset_2 = data.drop([\n",
    "    'LinearSlope',\n",
    "    'SPARC',\n",
    "    'RatioBeyondRSigma',\n",
    "    'Mean',\n",
    "    'Kurtosis', \n",
    "    'PowerSpectralSum',\n",
    "    'IQR',\n",
    "    'RangeCountPercentage',\n",
    "    'DominantFrequencyValue',\n",
    "    'ComplexityInvariantDistance'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.91 (0.04)\n",
      "Average Precision: 0.79 (0.11)\n",
      "Average Recall: 0.84 (0.14)\n",
      "Average F1 Score: 0.80 (0.09)\n"
     ]
    }
   ],
   "source": [
    "xgb_s_mdls, xgb_s_fts, xgb_s_accu, xgb_s_prec, xgb_s_rec, xgb_s_f1 = xgb_LOSO_runner(data_subset_2, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfe1500b00e4a289d5a3999f55bd1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_xgb_feature_gains(xgb_s_mdls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.90 (0.04)\n",
      "Average Precision: 0.76 (0.12)\n",
      "Average Recall: 0.83 (0.15)\n",
      "Average F1 Score: 0.78 (0.10)\n"
     ]
    }
   ],
   "source": [
    "xgb_de_mdls, xgb_de_fts, xgb_de_accu, xgb_de_prec, xgb_de_rec, xgb_de_f1 = xgb_LOSO_runner(de_data, training_masks, validation_masks, testing_masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-class Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.71 (0.11)\n",
      "Average Precision: 0.44 (0.20)\n",
      "Average Recall: 0.84 (0.12)\n",
      "Average F1 Score: 0.56 (0.18)\n"
     ]
    }
   ],
   "source": [
    "IF = IsolationForest(n_estimators=20)\n",
    "\n",
    "if_mdls, if_fts, *if_metr = unary_LOSO_runner(data, IF, *masks, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.80 (0.05)\n",
      "Average Precision: 0.54 (0.16)\n",
      "Average Recall: 0.44 (0.19)\n",
      "Average F1 Score: 0.46 (0.16)\n"
     ]
    }
   ],
   "source": [
    "usvc = OneClassSVM(kernel='rbf')\n",
    "\n",
    "usvc_mdls, _, *usvc_metr = unary_LOSO_runner(data, usvc, *masks, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
